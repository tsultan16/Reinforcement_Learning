{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Q learning: Linear Q-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a linear Q function class\n",
    "class LinearQ():\n",
    "\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        # initialize weights to zero\n",
    "        num_weights = self.features.get_num_actions() * self.features.get_num_features() \n",
    "        self.weights = np.zeros(shape=(num_weights)) \n",
    "\n",
    "\n",
    "    # update the weights\n",
    "    def update(self, state, action, delta):\n",
    "        # extract features from state\n",
    "        feature_values = self.features.extract(state, action)\n",
    "        # update weights\n",
    "        self.weights += delta * feature_values\n",
    "\n",
    "\n",
    "    # evaluate q function\n",
    "    def evaluate(self, state, action):\n",
    "        # extract features from state\n",
    "        feature_values = self.features.extract(state, action)\n",
    "        # compute Q value\n",
    "        Q = np.dot(feature_values, self.weights)\n",
    "        return Q\n",
    "\n",
    "\n",
    "# defining a feature extractor class for gridworld problem (hand-engineered features)\n",
    "class GridWorldFeatures:\n",
    "    def __init__(self, mdp):\n",
    "        self.mdp = mdp\n",
    "        self.num_features = 3\n",
    "        \n",
    "\n",
    "    def get_num_features(self):\n",
    "        return self.num_features    \n",
    " \n",
    " \n",
    "    def get_num_actions(self):\n",
    "        return len(self.mdp.get_actions())\n",
    "\n",
    "\n",
    "    '''\n",
    "        We will define three features:\n",
    "        1) x-distance from goal\n",
    "        2) y-distance from goal\n",
    "        3) manhattan distance from goal\n",
    "    '''\n",
    "    def extract_features(self, state, action):\n",
    "        (xg, yg) = self.mdp.goal\n",
    "        (x, y) = state\n",
    "        e = 0.01  # small additive value for avoiding division by zero        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
