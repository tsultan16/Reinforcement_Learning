{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "import math, time, random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a base Class for the tree nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    # static counter for node IDs\n",
    "    next_node_id = 0\n",
    "\n",
    "    # static dictionary for recording the number of times each node in the tree has been visited\n",
    "    visits = defaultdict(lambda: 0)\n",
    "\n",
    "    def __init__(self, mdp, parent, state, qfunction, bandit, reward=0.0, action=None):\n",
    "        self.mdp = mdp\n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.id = Node.next_node_id\n",
    "        Node.next_node_id += 1\n",
    "\n",
    "        # initialize Q function\n",
    "        self.qfunction = qfunction\n",
    "\n",
    "        # multi-armed bandit for node selection\n",
    "        self.bandit = bandit\n",
    "\n",
    "        # immediate reward received for transitioning into this state\n",
    "        self.reward = reward\n",
    "\n",
    "        # action that generated this node\n",
    "        self.action = action\n",
    "\n",
    "    # select a node that hasn't been fully expanded, i.e. leaf node\n",
    "    def select(self): abstractmethod\n",
    "\n",
    "    # expand a node if it is non-terminal state\n",
    "    def expand(self): abstractmethod\n",
    "\n",
    "    # backpropagate accumulate reward to the root node\n",
    "    def backpropagate(self): abstractmethod\n",
    "\n",
    "    # return V of this node\n",
    "    def get_value(self):\n",
    "        _, value = self.qfunction.get_maxQ(self.state, self.mdp.get_actions(self.state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class implementing the MCTS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, mdp, qfunction, bandit):\n",
    "        self.mdp = mdp\n",
    "        self.qfunction = qfunction\n",
    "        self.bandit = bandit\n",
    "\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, root_node=None):\n",
    "        # create a root node if none provided\n",
    "        if root_node == None:\n",
    "            root_node = self.create_root_node()\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout:\n",
    "\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            \n",
    "            if not (self.mdp.is_exit(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                selected_node.backpropagate(reward, child) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "\n",
    "        print(f\"MCTS iterations: {num_iterations}\")\n",
    "\n",
    "        # update value function and display the table\n",
    "        self.qfunction.update_V_from_Q()\n",
    "        self.qfunction.display()  \n",
    "\n",
    "        return root_node\n",
    "\n",
    "\n",
    "    # createa a root node representing the initial state\n",
    "    def create_root_node(self): abstractmethod       \n",
    "\n",
    "\n",
    "    # choose a random action for monte carlo simulation (can use a heuristic to choose actions instead of picking at random)\n",
    "    def choose(self, state):\n",
    "        actions = self.mdp.get_actions(state)\n",
    "        \n",
    "        # choose actions randomly\n",
    "        next_action = random.choice(actions)\n",
    "        \n",
    "        # heuristic based:  choose action that can lead to a state with highest immediate reward\n",
    "        '''\n",
    "        max_reward = float(\"-inf\")\n",
    "        max_actions = [] \n",
    "        for action in actions:\n",
    "            transitions = self.mdp.get_transitions(state, action)\n",
    "            for (next_state, _) in transitions:\n",
    "                reward = self.mdp.get_rewards(state, action, next_state)\n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    max_actions = [action]\n",
    "                elif reward == max_reward:\n",
    "                    max_actions.append(action)\n",
    "\n",
    "        # if multiple actions lead to best reward state,. pick one randomly\n",
    "        next_action = random.choice(max_actions)                 \n",
    "        '''\n",
    "        \n",
    "        return next_action\n",
    "    \n",
    "    \n",
    "    # run simulation until terminal state reached (can be stopped after a fixed number of time steps instead of running until reaching terminal state)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        cumulative_reward = 0.0\n",
    "        depth = 0\n",
    "\n",
    "        while not self.mdp.is_exit(state):\n",
    "            # choose an action to execute\n",
    "            action = self.choose(state)\n",
    "            # transition to next state\n",
    "            (next_state, reward) = self.mdp.execute(state, action)\n",
    "            # discount the reward\n",
    "            cumulative_reward += pow(self.mdp.gamma, depth) * reward \n",
    "            depth += 1\n",
    "            state = next_state\n",
    "\n",
    "        return cumulative_reward    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement derived classes for tree node and MCTS for single-agent MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAgentNode(Node):\n",
    "    \n",
    "    def __init__(self, mdp, parent, state, qfunction, bandit, reward=0, action=None):\n",
    "        super().__init__(mdp, parent, state, qfunction, bandit, reward, action)\n",
    "\n",
    "        # a dictionary from actions to node-probability pairs\n",
    "        self.children = {}\n",
    "\n",
    "\n",
    "    # checks if a node has been fully expanded\n",
    "    def is_fully_expanded(self):    \n",
    "        actions = self.mdp.get_actions(self.state)\n",
    "        if(len(actions) == len(self.children)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # recursively traverse the tree and select a node that has not been fully expanded yet\n",
    "    def select(self):\n",
    "\n",
    "        if not self.is_fully_expanded() or self.mdp.is_exit(self.state):\n",
    "            return self\n",
    "        else:\n",
    "            actions = list(self.children.keys())\n",
    "            action =  self.bandit.select(self.state, actions, self.qfunction)\n",
    "            return self.get_outcome_child(action).select()   \n",
    "\n",
    "\n",
    "    # expand a node if it's a non terminal-state\n",
    "    def expand(self):\n",
    "        if not self.mdp.is_exit(self.state):\n",
    "            # randomly select an unexpanded action to expand\n",
    "            unexplored_actions = self.mdp.get_actions(self.state) - self.children.keys()\n",
    "            action = random.choice(list(unexplored_actions))\n",
    "            # create a slot for that action in the children dictionary\n",
    "            self.children[action] = []\n",
    "            return self.get_outcome_child(action)\n",
    "        # for terminal state, can't expand further\n",
    "        return self\n",
    "\n",
    "\n",
    "    def get_outcome_child(self, action):\n",
    "        # choose one outcome state based on transition probabilities\n",
    "        (next_state, reward) = self.mdp.execute(self.state, action)\n",
    "\n",
    "        # check if this outcome state is already in the child set\n",
    "        for (child, _) in self.children[action]:\n",
    "            if next_state == child.state:\n",
    "                return child\n",
    "\n",
    "        # if this outcome did not occur before from this state-action pair, then create a new child node\n",
    "        new_child = SingleAgentNode(self.mdp, self, next_state, self.qfunction, self.bandit, reward, action)     \n",
    "        probability = 0.0\n",
    "        for (outcome, probability) in self.mdp.get_transitions(self.state, action):\n",
    "            if outcome == next_state:\n",
    "                self.children[action] += [(new_child, probability)]\n",
    "                return new_child       \n",
    "\n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G, child):\n",
    "        # get the action which generated the child\n",
    "        action = child.action\n",
    "\n",
    "        # update number of times visited for both the state (white) node and state-action (black) node\n",
    "        Node.visits[self.state] = Node.visits[self.state] + 1\n",
    "        Node.visits[(self.state, action)] = Node.visits[(self.state, action)] + 1\n",
    "\n",
    "        # get current Q value \n",
    "        qvalue = self.qfunction.evaluate(self.state, action)\n",
    "        # compute update delta\n",
    "        delta = (G - self.qfunction.evaluate(self.state, action)) / Node.visits[(self.state, action)]\n",
    "        # update the Q value\n",
    "        self.qfunction.update(self.state, action, qvalue, delta)\n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(self.reward + G, self)\n",
    "\n",
    "\n",
    "class SingleAgentMCTS(MCTS):\n",
    "\n",
    "    def __init__(self, mdp, qfunction, bandit):\n",
    "        super().__init__(mdp, qfunction, bandit)\n",
    "\n",
    "\n",
    "    def create_root_node(self, root_state=None):\n",
    "        if root_state == None:\n",
    "            return SingleAgentNode(self.mdp, None, self.mdp.get_initial_state(), self.qfunction, self.bandit)\n",
    "        else:\n",
    "            return SingleAgentNode(self.mdp, None, root_state, self.qfunction, self.bandit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test the MCTS on the gridworld problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# instantiate grid world mdp object\\ngw = GridWorld(discount_factor=0.9)\\n\\n# instantaiate Q table\\nqfunction = QTable(gw)\\n\\n# instantiate a bandit\\nbandit = UCBBandit()\\n\\n# instantiate MCTS solver\\nmcts_solver = SingleAgentMCTS(gw, qfunction, bandit)\\n\\n# run the mcts solver from the root node\\nroot_node = mcts_solver.mcts(1)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# instantiate grid world mdp object\n",
    "gw = GridWorld(discount_factor=0.9)\n",
    "\n",
    "# instantaiate Q table\n",
    "qfunction = QTable(gw)\n",
    "\n",
    "# instantiate a bandit\n",
    "bandit = UCBBandit()\n",
    "\n",
    "# instantiate MCTS solver\n",
    "mcts_solver = SingleAgentMCTS(gw, qfunction, bandit)\n",
    "\n",
    "# run the mcts solver from the root node\n",
    "root_node = mcts_solver.mcts(1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the best action according to our MCTS policy from the initial state (0,0) is up which is consistent with the optimal policy for this problem. Now lets use MCTS to execute a sequence of actions and check the policy at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MCTS...\n",
      "MCTS iterations: 2252\n",
      "-----------------------\n",
      " 0.08  0.13  0.28  0.00 \n",
      " 0.07  0.00  0.02  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  up     right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (0, 0), best_action: up, next state: (0, 1)\n",
      "New root node state: (0, 1)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4206\n",
      "-----------------------\n",
      " 0.10  0.14  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  right  right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (0, 1), best_action: up, next state: (0, 2)\n",
      "New root node state: (0, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3187\n",
      "-----------------------\n",
      " 0.10  0.14  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  down   right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (0, 2), best_action: right, next state: (1, 2)\n",
      "New root node state: (1, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4093\n",
      "-----------------------\n",
      " 0.10  0.14  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  up     right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (1, 2), best_action: up, next state: (1, 2)\n",
      "New root node state: (1, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4301\n",
      "-----------------------\n",
      " 0.10  0.14  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  up     right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (1, 2), best_action: up, next state: (1, 2)\n",
      "New root node state: (1, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 9559\n",
      "-----------------------\n",
      " 0.10  0.14  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  right  right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (1, 2), best_action: right, next state: (2, 2)\n",
      "New root node state: (2, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 16082\n",
      "-----------------------\n",
      " 0.10  0.15  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  right  right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (2, 2), best_action: right, next state: (2, 1)\n",
      "New root node state: (2, 1)\n",
      "Running MCTS...\n",
      "MCTS iterations: 16461\n",
      "-----------------------\n",
      " 0.10  0.15  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  right  right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (2, 1), best_action: up, next state: (2, 2)\n",
      "New root node state: (2, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 16829\n",
      "-----------------------\n",
      " 0.10  0.16  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  right  right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (2, 2), best_action: right, next state: (3, 2)\n",
      "New root node state: (3, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 99621\n",
      "-----------------------\n",
      " 0.10  0.16  0.28  0.00 \n",
      " 0.09  0.00  0.09  0.00 \n",
      " 0.04  0.00 -0.27  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  right  right  end    \n",
      "up     None   up     end    \n",
      "up     left   left   up     \n",
      "-----------------------\n",
      "s0 = (3, 2), best_action: end, next state: (-1, -1)\n",
      "New root node state: (-1, -1)\n",
      "Reached termimnal state\n"
     ]
    }
   ],
   "source": [
    "# instantiate grid world mdp object\n",
    "gw2 = GridWorld(discount_factor=0.9)\n",
    "\n",
    "# instantaiate Q table\n",
    "qfunction2 = QTablePartial(gw2)\n",
    "\n",
    "# instantiate a bandit\n",
    "bandit2 = UCBBandit()\n",
    "\n",
    "# instantiate MCTS solver\n",
    "mcts_solver2 = SingleAgentMCTS(gw2, qfunction2, bandit2)\n",
    "\n",
    "# set the initial state of the mdp as the root node\n",
    "node = mcts_solver2.create_root_node()\n",
    "\n",
    "max_steps = 100\n",
    "steps = 0\n",
    "\n",
    "while not gw2.is_exit(node.state) and steps < max_steps:\n",
    "\n",
    "    # run MCTS \n",
    "    print(f\"Running MCTS...\")\n",
    "    node = mcts_solver2.mcts(0.5, node)\n",
    "    best_action, _ = qfunction2.get_maxQ(node.state, gw2.get_actions(node.state))   \n",
    "\n",
    "    # transition to next state using the best action\n",
    "    (next_state, _) = gw2.execute(node.state, best_action) \n",
    "    print(f\"s0 = {node.state}, best_action: {gw2.action_names[best_action]}, next state: {next_state}\")\n",
    "\n",
    "    \n",
    "    ''' \n",
    "    # set the child node corresponding to the next state as new root node\n",
    "    for (child, probability) in node.children[best_action]:\n",
    "        print(f\"Child state: {child.state}, Probability: {probability}\")\n",
    "        if child.state == next_state:\n",
    "            node = child\n",
    "            break\n",
    "    # disconnect with old parent node    \n",
    "    node.parent = None\n",
    "    '''\n",
    "\n",
    "    # generate a new root node with the next state\n",
    "    node = mcts_solver2.create_root_node(root_state=next_state)\n",
    "\n",
    "    steps += 1\n",
    "    print(f\"New root node state: {node.state}\")\n",
    "       \n",
    "print(\"Reached termimnal state\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now testing on CliffWorld problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# instantiate grid world mdp object\\ncw = CliffWorld(discount_factor=0.9, noise=0.0)\\n\\n# instantaiate Q table\\nqfunction = QTable(cw)\\n\\n# instantiate a bandit\\nbandit = UCBBandit()\\n\\n# instantiate MCTS solver\\nmcts_solver = SingleAgentMCTS(cw, qfunction, bandit)\\n\\n# run the mcts solver\\nroot_node = mcts_solver.mcts(1)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# instantiate grid world mdp object\n",
    "cw = CliffWorld(discount_factor=0.9, noise=0.0)\n",
    "\n",
    "# instantaiate Q table\n",
    "qfunction = QTable(cw)\n",
    "\n",
    "# instantiate a bandit\n",
    "bandit = UCBBandit()\n",
    "\n",
    "# instantiate MCTS solver\n",
    "mcts_solver = SingleAgentMCTS(cw, qfunction, bandit)\n",
    "\n",
    "# run the mcts solver\n",
    "root_node = mcts_solver.mcts(1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MCTS...\n",
      "MCTS iterations: 7500\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.00 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     up     down   up     \n",
      "up     up     up     up     down   up     \n",
      "up     up     up     down   left   up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 0), best_action: up, next state: (0, 1)\n",
      "Running MCTS...\n",
      "MCTS iterations: 7212\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.00 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     up     up     up     \n",
      "right  up     up     up     right  up     \n",
      "up     down   up     down   right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 1), best_action: up, next state: (0, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 6884\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     up     down   left   \n",
      "up     up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 2), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3878\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     up     left   left   \n",
      "up     up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3988\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  left   left   \n",
      "up     up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3880\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     up     up     left   \n",
      "up     up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3928\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  down   down   \n",
      "up     up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3475\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  down   down   \n",
      "right  up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3624\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  down   down   \n",
      "right  up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3661\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     up     up     down   \n",
      "right  up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: up, next state: (0, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3271\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  0.61 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "right  up     up     right  down   down   \n",
      "right  up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (0, 3), best_action: right, next state: (1, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3930\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  up     right  \n",
      "right  up     up     up     right  up     \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (1, 3), best_action: up, next state: (1, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4122\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "left   up     up     right  left   right  \n",
      "right  up     up     up     up     left   \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (1, 3), best_action: up, next state: (1, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4047\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  right  right  \n",
      "right  up     up     up     up     left   \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (1, 3), best_action: up, next state: (1, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3945\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  0.00 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     up     right  right  right  \n",
      "right  up     up     up     up     left   \n",
      "up     down   up     up     right  up     \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (1, 3), best_action: up, next state: (1, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4159\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     right  up     right  right  right  \n",
      "right  up     up     up     up     right  \n",
      "up     up     up     up     right  right  \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (1, 3), best_action: right, next state: (2, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3759\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     up     right  right  \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (2, 3), best_action: right, next state: (3, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3479\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     up     right  right  \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (3, 3), best_action: right, next state: (4, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3205\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     up     right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (4, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3444\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     up     right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4099\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     up     down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3669\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     up     down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3324\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     up     down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4376\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  down   \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     up     down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: down, next state: (5, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4900\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     up     right  \n",
      "up     up     up     up     right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 2), best_action: right, next state: (5, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 5041\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 2), best_action: up, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3635\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3737\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: up, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3640\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3477\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: up, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3686\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3710\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3519\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3418\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3573\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: up, next state: (4, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4284\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (4, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3419\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     up     up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3539\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3353\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3375\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3745\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   down   down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 3)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3874\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  right  \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 3), best_action: right, next state: (5, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 3666\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  right  \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 2), best_action: up, next state: (4, 2)\n",
      "Running MCTS...\n",
      "MCTS iterations: 4439\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     right  right  \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (4, 2), best_action: right, next state: (4, 1)\n",
      "Running MCTS...\n",
      "MCTS iterations: 23633\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (4, 1), best_action: right, next state: (5, 1)\n",
      "Running MCTS...\n",
      "MCTS iterations: 45504\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 1), best_action: down, next state: (5, 0)\n",
      "Running MCTS...\n",
      "MCTS iterations: 184537\n",
      "-----------------------\n",
      "-2.43 -2.54 -2.37 -2.04  0.07  2.01 \n",
      "-1.92 -0.57 -0.32 -2.05  0.37  0.00 \n",
      "-2.83 -4.34 -1.24 -5.34  0.26  1.19 \n",
      "-4.22  0.00  0.00  0.00  0.00  0.00 \n",
      "-----------------------\n",
      "-----------------------\n",
      "up     up     right  right  right  up     \n",
      "right  up     up     up     right  up     \n",
      "up     up     up     down   right  down   \n",
      "up     end    end    end    end    end    \n",
      "-----------------------\n",
      "s0 = (5, 0), best_action: end, next state: (-1, -1)\n",
      "Reached termimnal state\n"
     ]
    }
   ],
   "source": [
    "# instantiate grid world mdp object\n",
    "cw = CliffWorld(discount_factor=0.9, noise=0.1)\n",
    "\n",
    "# instantaiate Q table\n",
    "qfunction3 = QTablePartial(cw)\n",
    "\n",
    "# instantiate a bandit\n",
    "bandit3 = UCBBandit()\n",
    "\n",
    "# instantiate MCTS solver\n",
    "mcts_solver3 = SingleAgentMCTS(cw, qfunction3, bandit3)\n",
    "\n",
    "# set the initial state of the mdp as the root node\n",
    "node = mcts_solver3.create_root_node()\n",
    "\n",
    "max_steps = 100\n",
    "steps = 0\n",
    "\n",
    "while not cw.is_exit(node.state) and steps < max_steps:\n",
    "\n",
    "    # run MCTS for 1 second\n",
    "    print(f\"Running MCTS...\")\n",
    "    node = mcts_solver3.mcts(1.0, node)\n",
    "    best_action, _ = qfunction3.get_maxQ(node.state, cw.get_actions(node.state))   \n",
    "\n",
    "    # transition to next state using the best action\n",
    "    (next_state, _) = cw.execute(node.state, best_action) \n",
    "    print(f\"s0 = {node.state}, best_action: {cw.action_names[best_action]}, next state: {next_state}\")\n",
    "\n",
    "    # set the child node corresponding to the next state as new root node\n",
    "    '''\n",
    "    for (child, probability) in node.children[best_action]:\n",
    "        print(f\"Child state: {child.state}, Probability: {probability}\")\n",
    "        if child.state == next_state:\n",
    "            node = child\n",
    "            break\n",
    "    # disconnect with old parent node    \n",
    "    node.parent = None    \n",
    "    '''\n",
    "\n",
    "    # generate a new root node with the next state\n",
    "    node = mcts_solver3.create_root_node(root_state=next_state)\n",
    "    # reset Q function to zeros\n",
    "    #qfunction3.reset()\n",
    "\n",
    "    steps += 1\n",
    "       \n",
    "print(\"Reached termimnal state\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
