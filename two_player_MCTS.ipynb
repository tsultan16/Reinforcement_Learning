{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "import math, time, random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-player Monte Carlo Tree Search: For turn based games where actions are alternatingly carried out by an agent and it's opponent. We will demonstrate monte carlo search using the Tic Tac Toe game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a base class for game tree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "\n",
    "    # static counter for node IDs\n",
    "    next_node_id = 0\n",
    "\n",
    "    # static dictionary for recording the number of times each node in the tree has been visited\n",
    "    visits = defaultdict(lambda: 0)\n",
    "\n",
    "    def __init__(self, state, player_turn, value, is_best_action=False, children=dict()):\n",
    "        self.state = state\n",
    "        self.player_turn = player_turn  # marks which player's turn is on that state\n",
    "        self.value = value\n",
    "        self.is_best_action = is_best_action\n",
    "        self.children = children\n",
    "\n",
    "        self.id = GameNode.next_node_id\n",
    "        GameNode.next_node_id += 1\n",
    "        \n",
    "    # select a node that hasn't been fully expanded, i.e. leaf node\n",
    "    def select(self): abstractmethod\n",
    "\n",
    "    # expand a node if it is non-terminal state\n",
    "    def expand(self): abstractmethod\n",
    "\n",
    "    # backpropagate accumulate reward to the root node\n",
    "    def backpropagate(self): abstractmethod\n",
    "\n",
    "    # return value of this node\n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class for the tic tac toe game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = ' '\n",
    "CIRCLE = 'O'\n",
    "CROSS = 'X'\n",
    "\n",
    "class TicTacToe:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.players = [CIRCLE, CROSS]\n",
    "\n",
    "    # get list of players\n",
    "    def get_players(self):\n",
    "        return self.players\n",
    "    \n",
    "    # get all valid actions from a state (a valid action is just an empty position on the board which can be marked by a player)\n",
    "    def get_actions(self, state):\n",
    "        board = state\n",
    "        actions = []\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    actions += [(i,j)]\n",
    "            \n",
    "        return actions\n",
    "\n",
    "\n",
    "    # make deep copy of a state\n",
    "    def copy(self, state):\n",
    "        next_state = []\n",
    "        for i in range(len(state)):\n",
    "            new_row = []\n",
    "            for j in range(len(state[i])):\n",
    "                new_row += [state[i][j]]\n",
    "            next_state += [new_row]    \n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "\n",
    "    # return the state reulting from playing an action from a state\n",
    "    def get_transition(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return next_state\n",
    "\n",
    "\n",
    "    # return all possible auccessors from the state\n",
    "    def get_successors(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            # if game is finished, there's no successor states\n",
    "            return set()\n",
    "        else:\n",
    "            successors = []\n",
    "            actions = self.get_actions(state)\n",
    "            for action in actions:\n",
    "                successors += [self.get_transition(state, action)]\n",
    "            \n",
    "            return successors\n",
    "\n",
    "\n",
    "    # return the reward for transitioning into the state\n",
    "    def get_reward(self, state):\n",
    "        winner = self.get_winner(state)\n",
    "        if winner == None:\n",
    "            return {CROSS: 0, CIRCLE: 0}\n",
    "        \n",
    "        elif winner == CROSS:\n",
    "            return {CROSS: 1, CIRCLE: 0}\n",
    "\n",
    "        elif winner == CIRCLE:\n",
    "            return {CROSS: 0, CIRCLE: 1}\n",
    "\n",
    "\n",
    "    # count how many empty positions on the board\n",
    "    def count_empty(self, board):\n",
    "        empty = 0\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    empty += 1\n",
    "\n",
    "        return empty\n",
    "    \n",
    "    # return true iff state is a terminal state of the game\n",
    "    def is_terminal(self, state):\n",
    "        return self.count_empty(state)==0 or self.get_winner(state) != None\n",
    "    \n",
    "    # return player who gets to select the action at current state, i.e. whose turn it is\n",
    "    def get_player_turn(self, state):\n",
    "        board = state\n",
    "        # cross always starts the game, so crosses turn if there are an odd number of empty cells (9 cells total)\n",
    "        empty = self.count_empty(board)\n",
    "        if empty %2 == 0:\n",
    "            return CIRCLE\n",
    "        else:\n",
    "            return CROSS\n",
    "\n",
    "\n",
    "    # initial state of the game (empty board)\n",
    "    def initial_state(self):\n",
    "        board = [[EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY]]\n",
    "\n",
    "        return board\n",
    "\n",
    "    def get_winner(self, state):\n",
    "        board = state\n",
    "\n",
    "        # check rows\n",
    "        for i in range(len(board)):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board[i]):\n",
    "                return CROSS      \n",
    "            elif circles == len(board[i]):\n",
    "                return CIRCLE \n",
    "       \n",
    "        # check columns\n",
    "        for j in range(len(board[0])):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for i in range(len(board)):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board):\n",
    "                return CROSS      \n",
    "            elif circles == len(board):\n",
    "                return CIRCLE \n",
    "\n",
    "        # check top-left to bottom-right diagonal\n",
    "        if board[0][0] == CIRCLE and board[1][1] == CIRCLE and board[2][2] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][0] == CROSS and board[1][1] == CROSS and board[2][2] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # check top-right to bottom-left diagonal\n",
    "        if board[0][2] == CIRCLE and board[1][1] == CIRCLE and board[2][0] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][2] == CROSS and board[1][1] == CROSS and board[2][0] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # no winner\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # format the board into a string\n",
    "    def display_board(self, state):\n",
    "        for row in state:\n",
    "            for i in range(len(row)):        \n",
    "                if i < len(row)-1:\n",
    "                    print(row[i], end=' | ')\n",
    "                else:\n",
    "                    print(row[i], end='')    \n",
    "            print()\n",
    "\n",
    "    def game_tree(self):\n",
    "        return self.state_to_node(self.get_initial_state())\n",
    "    \n",
    "\n",
    "    def state_to_node(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            return GameNode(state, None, self.get_reward(state))\n",
    "        \n",
    "        player = self.get_player_turn(state)\n",
    "        children = dict()\n",
    "        for action in self.get_actions(state):\n",
    "            next_state = self.get_transition(state, action)\n",
    "            child_node = self.state_to_node(next_state)\n",
    "            children[action] = child_node\n",
    "        \n",
    "        return GameNode(state, player, None, children)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now define an MCTS class for the tic tac toe game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, game, exploration_weight=1.0):\n",
    "        self.game = game\n",
    "\n",
    "        # dictionary for storing value/total reward at each node\n",
    "        self.Q = defaultdict(int)\n",
    "        # dictionary for storing visit counts for each node\n",
    "        self.visited = defaultdict(int)\n",
    "        # dictionary for storing children of expanded nodes\n",
    "        self.children = dict()\n",
    "        self.exploration_weight = exploration_weight\n",
    "\n",
    "                    \n",
    "    # choose a move in the game \n",
    "    def choose_move(self, node):\n",
    "        # make sure the state is not terminal\n",
    "        if self.game.is_terminal(node.state):\n",
    "            raise RuntimeError(f\"choose called on terminal state: {node.state}\")\n",
    "\n",
    "        # get all valid actions\n",
    "        actions = self.game.get_actions(node.state)\n",
    "        \n",
    "        if node not in self.children:\n",
    "            return random.choice(actions)\n",
    "        \n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\") # unseen moves have lowest possible value\n",
    "            else:\n",
    "                return self.Q[n] / self.N[n] # average reward\n",
    "\n",
    "        # return child with best value\n",
    "        return max(self.children[node], key=score)\n",
    "\n",
    "\n",
    "    # traverse down from a node and select a descendent node which has not been fully expanded yet\n",
    "    def select(self, node):\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored/unexpanded or terminal (i.e. node has no children)\n",
    "                return path\n",
    "            # get unexpanded nodes \n",
    "            unexplored = self.children[node] - self.children.keys()\n",
    "            if unexplored:\n",
    "                n = unexplored.pop()\n",
    "                path.append(n)\n",
    "                return path\n",
    "            \n",
    "            # if all children expanded, need to go another level deeper, select child using UCB bandit\n",
    "            node = self.ucb_select(node)\n",
    "            \n",
    "\n",
    "    # select successor node using ucb bandit\n",
    "    def ucb_select(self, node):\n",
    "        log_N = math.log(self.N[node])\n",
    "        def ucb(n):\n",
    "            return self.Q[n]/self.N[n] + self.exploration_weight * math.sqrt(log_N/self.N[n])\n",
    "        \n",
    "        return max(self.children[node], key=ucb)\n",
    "\n",
    "\n",
    "    # update the children dictionary with the children of node\n",
    "    def expand(self, node):\n",
    "        # node already expanded\n",
    "        if node in self.children:\n",
    "            return\n",
    "        self.children[node] = node.get_transitions()\n",
    "    \n",
    "\n",
    "    # run simulation until terminal state reached (can be stopped after a fixed number of time steps instead of running until reaching terminal state)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        cumulative_reward = 0.0\n",
    "        depth = 0\n",
    "        invert_reward = True\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if self.game.is_terminal(node.state):\n",
    "                reward = self.game.get_reward(state)\n",
    "                return 1- reward if invert_reward else reward \n",
    "            \n",
    "            node = random.choice(self.game.get_actions(node.state))\n",
    "\n",
    "            # choose an action to execute\n",
    "            action = self.choose(state)\n",
    "            # transition to next state\n",
    "            (next_state, reward) = self.mdp.execute(state, action)\n",
    "            # discount the reward\n",
    "            cumulative_reward += pow(self.mdp.gamma, depth) * reward \n",
    "            depth += 1\n",
    "            state = next_state\n",
    "\n",
    "        return cumulative_reward    \n",
    "\n",
    "\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, root_node=None):\n",
    "        # create a root node if none provided\n",
    "        if root_node == None:\n",
    "            root_node = self.create_root_node()\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout:\n",
    "\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            \n",
    "            if not (self.mdp.is_exit(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                selected_node.backpropagate(reward, child) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "\n",
    "        print(f\"MCTS iterations: {num_iterations}\")\n",
    "\n",
    "        # update value function and display the table\n",
    "        self.qfunction.update_V_from_Q()\n",
    "        self.qfunction.display()  \n",
    "\n",
    "        return root_node\n",
    " \n",
    "\n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G, child):\n",
    "        # get the action which generated the child\n",
    "        action = child.action\n",
    "\n",
    "        # update number of times visited for both the state (white) node and state-action (black) node\n",
    "        Node.visits[self.state] = Node.visits[self.state] + 1\n",
    "        Node.visits[(self.state, action)] = Node.visits[(self.state, action)] + 1\n",
    "\n",
    "        # get current Q value \n",
    "        qvalue = self.qfunction.evaluate(self.state, action)\n",
    "        # compute update delta\n",
    "        delta = (G - self.qfunction.evaluate(self.state, action)) / Node.visits[(self.state, action)]\n",
    "        # update the Q value\n",
    "        self.qfunction.update(self.state, action, qvalue, delta)\n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(self.reward + G, self)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
