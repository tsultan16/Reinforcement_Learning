{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "import math, time, random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-player Monte Carlo Tree Search: For turn based games where actions are alternatingly carried out by an agent and it's opponent. We will demonstrate monte carlo search using the Tic Tac Toe game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class for a tic tac toe game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = '-'\n",
    "CIRCLE = 'O'\n",
    "CROSS = 'X'\n",
    "\n",
    "class TicTacToe:\n",
    "\n",
    "    def __init__(self, gamma = 1.0):\n",
    "        self.players = [CIRCLE, CROSS]\n",
    "        self.CROSS = CROSS\n",
    "        self.CIRCLE = CIRCLE\n",
    "        self.gamma = 1.0\n",
    "\n",
    "    # get list of players\n",
    "    def get_players(self):\n",
    "        return self.players\n",
    "    \n",
    "    \n",
    "    def get_opponent(self, player):\n",
    "        if player == CIRCLE:\n",
    "            opponent = CROSS\n",
    "        else:\n",
    "            opponent = CIRCLE \n",
    "        return opponent       \n",
    "    \n",
    "    \n",
    "    # get all valid actions from a state (a valid action is just an empty position on the board which can be marked by a player)\n",
    "    def get_actions(self, state):\n",
    "        board = state\n",
    "        actions = []\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    actions += [(i,j)]\n",
    "            \n",
    "        return actions\n",
    "\n",
    "\n",
    "    # make deep copy of a state\n",
    "    def copy(self, state):\n",
    "        next_state = []\n",
    "        for i in range(len(state)):\n",
    "            new_row = []\n",
    "            for j in range(len(state[i])):\n",
    "                new_row += [state[i][j]]\n",
    "            next_state += [new_row]    \n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "\n",
    "    # return the reward and state reulting from playing an action from a state\n",
    "    def execute(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return (next_state, self.get_reward(next_state))\n",
    "\n",
    "\n",
    "    # return the state reulting from playing an action from a state\n",
    "    def get_transition(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return next_state\n",
    "\n",
    "\n",
    "    # return all possible successors from the state\n",
    "    def get_successors(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            # if game is finished, there's no successor states\n",
    "            return set()\n",
    "        else:\n",
    "            successors = []\n",
    "            actions = self.get_actions(state)\n",
    "            for action in actions:\n",
    "                successors += [self.get_transition(state, action)]\n",
    "            \n",
    "            return successors\n",
    "\n",
    "\n",
    "    # return the reward for transitioning into the state\n",
    "    def get_reward(self, state):\n",
    "        winner = self.get_winner(state)\n",
    "        if winner == None:\n",
    "            return {CROSS: 0.5, CIRCLE: 0.5}\n",
    "        \n",
    "        elif winner == CROSS:\n",
    "            return {CROSS: 1.0, CIRCLE: 0.0}\n",
    "\n",
    "        elif winner == CIRCLE:\n",
    "            return {CROSS: 0.0, CIRCLE: 1.0}\n",
    "\n",
    "\n",
    "    # count how many empty positions on the board\n",
    "    def count_empty(self, board):\n",
    "        empty = 0\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    empty += 1\n",
    "\n",
    "        return empty\n",
    "    \n",
    "    # return true iff state is a terminal state of the game\n",
    "    def is_terminal(self, state):\n",
    "        #if self.get_winner(state) != None:\n",
    "        #    print(f\"The winner is : {self.get_winner(state)}\")\n",
    "\n",
    "        return self.count_empty(state)==0 or self.get_winner(state) != None\n",
    "    \n",
    "    # return player who gets to select the action at current state, i.e. whose turn it is\n",
    "    def get_player_turn(self, state):\n",
    "        board = state\n",
    "        # cross always starts the game, so crosses turn if there are an odd number of empty cells (9 cells total)\n",
    "        empty = self.count_empty(board)\n",
    "        if empty %2 == 0:\n",
    "            return CIRCLE\n",
    "        else:\n",
    "            return CROSS\n",
    "\n",
    "\n",
    "    # initial state of the game (empty board)\n",
    "    def initial_state(self):\n",
    "        board = [[EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY]]\n",
    "\n",
    "        return board\n",
    "\n",
    "    def get_winner(self, state):\n",
    "        board = state\n",
    "\n",
    "        # check columns\n",
    "        for i in range(len(board)):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board[i]):\n",
    "                return CROSS      \n",
    "            elif circles == len(board[i]):\n",
    "                return CIRCLE \n",
    "       \n",
    "        # check rows\n",
    "        for j in range(len(board[0])):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for i in range(len(board)):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board):\n",
    "                return CROSS      \n",
    "            elif circles == len(board):\n",
    "                return CIRCLE \n",
    "\n",
    "        # check top-left to bottom-right diagonal\n",
    "        if board[0][0] == CIRCLE and board[1][1] == CIRCLE and board[2][2] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][0] == CROSS and board[1][1] == CROSS and board[2][2] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # check top-right to bottom-left diagonal\n",
    "        if board[0][2] == CIRCLE and board[1][1] == CIRCLE and board[2][0] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][2] == CROSS and board[1][1] == CROSS and board[2][0] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # no winner\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # format the board into a string\n",
    "    def display_board(self, state):\n",
    "        for row in state:\n",
    "            for i in range(len(row)):        \n",
    "                if i < len(row)-1:\n",
    "                    print(row[i], end=' | ')\n",
    "                else:\n",
    "                    print(row[i], end='')    \n",
    "            print()\n",
    "\n",
    "\n",
    "    '''\n",
    "    def game_tree(self):\n",
    "        return self.state_to_node(self.get_initial_state())\n",
    "    \n",
    "\n",
    "    def state_to_node(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            return GameNode(state, None, self.get_reward(state))\n",
    "        \n",
    "        player = self.get_player_turn(state)\n",
    "        children = dict()\n",
    "        for action in self.get_actions(state):\n",
    "            next_state = self.get_transition(state, action)\n",
    "            child_node = self.state_to_node(next_state)\n",
    "            children[action] = child_node\n",
    "        \n",
    "        return GameNode(state, player, None, children)    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a base class for game tree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "\n",
    "    # static counter for node IDs\n",
    "    next_node_id = 0\n",
    "\n",
    "    # static dictionary for recording the number of times each node in the tree has been visited\n",
    "    visits = defaultdict(lambda: 0)\n",
    "\n",
    "    def __init__(self, game, state, parent, player_turn, bandit, value=0.0, reward=0.0, is_best_action=False, children=dict(), action=None):\n",
    "        self.game = game\n",
    "        self.state = state\n",
    "        self.parent = parent            # pointer to parent node\n",
    "        self.player_turn = player_turn  # marks which player's turn is on that state\n",
    "        self.value = value\n",
    "        self.reward = reward\n",
    "        self.bandit = bandit\n",
    "        self.is_best_action = is_best_action\n",
    "        self.children = dict()\n",
    "        self.action = action # action which generated the child\n",
    "        self.accumulated_rewards = 0.0\n",
    "\n",
    "        self.id = GameNode.next_node_id\n",
    "        GameNode.next_node_id += 1\n",
    "        \n",
    "\n",
    "    # recursively traverse the tree and select a node that has not been fully expanded yet\n",
    "    def select(self):\n",
    "\n",
    "        if not self.is_fully_expanded() or self.game.is_terminal(self.state):\n",
    "            # stop recursion when we've found node which hasn't been fully expanded or is terminal state\n",
    "            return self\n",
    "        else:\n",
    "            # use the bandit to select the next child\n",
    "            actions = list(self.children.keys())\n",
    "            values = {action:self.children[action].get_value() for action in actions}\n",
    "            parent_visits = GameNode.visits[self.id]\n",
    "            children_visits = {action:GameNode.visits[self.children[action].id] for action in actions}\n",
    "            action =  self.bandit.select(actions, values, parent_visits, children_visits)\n",
    "            return self.children[action].select()  \n",
    "\n",
    "\n",
    "    # checks if a node has been fully expanded\n",
    "    def is_fully_expanded(self):    \n",
    "        actions = self.game.get_actions(self.state)\n",
    "        if(len(actions) == len(self.children)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    # expand a node (only generate one child, not all children) if it's a non terminal-state\n",
    "    def expand(self):\n",
    "        if not self.game.is_terminal(self.state):\n",
    "\n",
    "            #print(f\"Expanding node id: {self.id}\")\n",
    "\n",
    "            # randomly select an unexpanded action to expand\n",
    "            valid_actions = self.game.get_actions(self.state)\n",
    "            #print(f\"Available actions: {valid_actions}, already expanded children actions: {list(self.children.keys())}\")\n",
    "\n",
    "            unexplored_actions = list(valid_actions - self.children.keys())\n",
    "            #print(f\"Unexplored actions: {unexplored_actions}\")\n",
    "\n",
    "            #if len(unexplored_actions) > 0:\n",
    "            action = random.choice(unexplored_actions)\n",
    "            #else:\n",
    "            #    action = random.choice(list(self.children.keys()))\n",
    "\n",
    "            #print(f\"randomly chosen action = {action}\")\n",
    "            # create a slot for that action in the children dictionary\n",
    "            #self.children[action] = []\n",
    "\n",
    "            # create a new child node and add to children dictionary\n",
    "            (child_state, reward) = self.game.execute(self.state, action)\n",
    "            new_child = GameNode(self.game, child_state, self, self.game.get_opponent(self.player_turn), self.bandit, reward=reward, action=action, children=dict())    \n",
    "            self.children[action] = new_child  # each action leads to only one child \n",
    "            #print(f\"generated child id: {new_child.id}, expanded children actions: {list(new_child.children.keys())}\")\n",
    "            \n",
    "            #print(f\"Genereated child node id: {self.children[action].id}, action: {action}, board state:\")\n",
    "            #self.game.display_board(self.children[action].state)\n",
    "            \n",
    "            return new_child                   \n",
    "        \n",
    "        # for terminal state, can't expand further\n",
    "        return self\n",
    "    \n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G):\n",
    "\n",
    "        # update number of times visited for the state\n",
    "        GameNode.visits[self.id] = GameNode.visits[self.id] + 1\n",
    "\n",
    "        # apply discount to the backpropagated reward\n",
    "        discounted_G = {}\n",
    "        for player in G:\n",
    "            discounted_G[player] = G[player] * self.game.gamma   \n",
    "\n",
    "        # update the accumulated reward\n",
    "        #simulation_reward = discounted_G[self.player_turn]  \n",
    "        simulation_reward = discounted_G[self.game.get_opponent(self.player_turn)]  # this seems to make it work, even though it's the opposite of what it should be ... \n",
    "        self.accumulated_rewards += simulation_reward \n",
    "\n",
    "        #print(f\"Backpropagation. Node id: {self.id}, visited: {GameNode.visits[self.id]}, accumulated reward: {self.accumulated_rewards}\")\n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(discounted_G)\n",
    "\n",
    "\n",
    "    # return value of this node\n",
    "    def get_value(self):\n",
    "        return self.accumulated_rewards / GameNode.visits[self.id] \n",
    "\n",
    "\n",
    "\n",
    "# upper confidence bounds (UCB) bandit\n",
    "class UCBBandit:\n",
    "    def __init__(self, exploration_param = 1.0):\n",
    "        self.total = 0\n",
    "        # dictionary for recording number of times each action has been chosen\n",
    "        self.times_selected = {}\n",
    "        self.exploration_param = exploration_param\n",
    "\n",
    "\n",
    "    def select(self, actions, values, parent_visits, children_visits):\n",
    "        '''       \n",
    "        # first, make sure each action has been executed once\n",
    "        for action in actions:\n",
    "            if action not in self.times_selected.keys():\n",
    "                self.times_selected[action] = 1\n",
    "                self.total += 1\n",
    "                return action\n",
    "\n",
    "        max_actions = []\n",
    "        max_value = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            value = values[action] + self.exploration_param * math.sqrt(2.0*math.log(parent_visits)/children_visits[action])\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_actions = [action]\n",
    "            elif value == max_value:\n",
    "                max_actions.append(action)\n",
    "\n",
    "        '''\n",
    "        max_actions = []\n",
    "        max_value = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            # avoid division by zero\n",
    "            if children_visits[action] == 0 or parent_visits == 0:\n",
    "                value = float(\"inf\")\n",
    "            else: \n",
    "                value = values[action] + self.exploration_param * math.sqrt(2.0*math.log(parent_visits)/children_visits[action])\n",
    "                \n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_actions = [action]\n",
    "            elif value == max_value:\n",
    "                max_actions.append(action)\n",
    "\n",
    "\n",
    "        # if multiple actions with max value, pick one randomly\n",
    "        selected_action = random.choice(max_actions)\n",
    "        #self.times_selected[selected_action] = self.times_selected[selected_action] + 1\n",
    "        #self.total += 1\n",
    "        \n",
    "        return selected_action    \n",
    "    \n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, bandit):\n",
    "        self.game = game\n",
    "        self.bandit = bandit\n",
    "\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, initial_root_node=None, root_state=None, player_turn=None):\n",
    "        # create a root node if none provided\n",
    "        #if root_node == None:\n",
    "        root_node = self.create_root_node(root_state=root_state, player_turn=player_turn)\n",
    "        #root_node = GameNode(self.game, root_state, None, player_turn, self.bandit)  \n",
    "        #root_node.children = dict()\n",
    "        #print(f\"root node id: {root_node.id}, children: {list(root_node.children.keys())}\")\n",
    "        #print(f\"Initial game state:\")\n",
    "        #self.game.display_board(root_state)\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout and num_iterations<250:\n",
    "\n",
    "            #print(f\"MCTS iteration # {num_iterations}\")\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            #print(f\"selected node id: {selected_node.id}\")\n",
    "\n",
    "            if not (self.game.is_terminal(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "                #print(f\"Child node id: {child.id}\")\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "                #print(f\"Simulation rewards: {reward}\")\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                child.backpropagate(reward) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "        #print(f\"MCTS iterations: {num_iterations}\")\n",
    "        # after finishing mcts iterations, find the best action\n",
    "        best_action = self.get_best_action(root_node)\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    # get the best action from the root node\n",
    "    def get_best_action(self, root_node):\n",
    "\n",
    "        #print(f\"choosing best action.. Root node id: {root_node.id}, Root node state:\")\n",
    "        #self.game.display_board(root_node.state)\n",
    "        #print(f\"Available children/actions: {list(root_node.children.keys())}\")\n",
    "\n",
    "        best_action = None\n",
    "        best_value = float(\"-inf\")\n",
    "        for i, action in enumerate(root_node.children.keys()):\n",
    "\n",
    "            #print(f\"Child node id: {root_node.children[action].id}, action: {action}, board state:\")\n",
    "            #self.game.display_board(root_node.children[action].state)\n",
    "\n",
    "            value = root_node.children[action].get_value()\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_action = [action]\n",
    "            elif value == best_value:\n",
    "                best_action.append(action)\n",
    "\n",
    "        # if multiple best actions, use random sampling\n",
    "        return random.choice(best_action)    \n",
    "\n",
    "\n",
    "    # create a root node representing the initial state\n",
    "    def create_root_node(self, root_state=None, player_turn=None):\n",
    "        if root_state == None:\n",
    "            return GameNode(self.game, self.game.initial_state(), None, self.game.CROSS, self.bandit) # cross gets first turn\n",
    "        else:\n",
    "            return GameNode(self.game, root_state, None, player_turn, self.bandit)  \n",
    "\n",
    "\n",
    "    # choose a random action for monte carlo simulation (can use a heuristic to choose actions instead of picking at random)\n",
    "    def choose(self, state):\n",
    "        actions = self.game.get_actions(state)\n",
    "        \n",
    "        # choose actions randomly\n",
    "        next_action = random.choice(actions)\n",
    "                \n",
    "        return next_action\n",
    "    \n",
    "    \n",
    "    # run simulation until terminal state reached (can be stopped after a fixed number of time steps instead of running until reaching terminal state)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        # the second entry in the reward vector is for opponent agent\n",
    "        player = node.player_turn\n",
    "        opponent = self.game.get_opponent(node.player_turn)\n",
    "        cumulative_reward = {player:0.0, opponent:0.0}\n",
    "        depth = 0\n",
    "\n",
    "        #print(f\"simulation initial state: \")\n",
    "        #self.game.display_board(state)\n",
    "        reward = None\n",
    "        while not self.game.is_terminal(state):\n",
    "            # choose an action to execute\n",
    "            action = self.choose(state)\n",
    "            # transition to next state\n",
    "            (next_state, reward) = self.game.execute(state, action)\n",
    "            # discount the rewards for my agent and opponent agent\n",
    "            cumulative_reward[player] = cumulative_reward[player] + pow(self.game.gamma, depth) * reward[player] \n",
    "            cumulative_reward[opponent] = cumulative_reward[opponent] +pow(self.game.gamma, depth) * reward[opponent] \n",
    "            depth += 1\n",
    "            state = next_state\n",
    "\n",
    "            #print(f\"Next state: \")\n",
    "            #self.game.display_board(state)\n",
    "\n",
    "        #print(f\"Terminal state reached! Simulation completed. Rewards: {reward}\")\n",
    "\n",
    "        return cumulative_reward    \n",
    "    \n",
    "\n",
    "\n",
    "# self play function\n",
    "def self_play(num_games, random_X=False, random_O=False):\n",
    "\n",
    "    # instantiate ganme object\n",
    "    game = TicTacToe()\n",
    "    # instantiate bandit\n",
    "    bandit = UCBBandit()\n",
    "    # instantiate MCTS solver\n",
    "    mcts_solver = MCTS(game, bandit)\n",
    "\n",
    "    wins = {'X':0, 'O':0, 'Draw':0}\n",
    "    \n",
    "    with tqdm(total=num_games, ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "\n",
    "        # first turn goes to X\n",
    "        player_turn = 'X'\n",
    "        for i in range(num_games):\n",
    "            steps = 0\n",
    "            game_state = game.initial_state()\n",
    "            #print(f\"Starting game # {i}\")\n",
    "            while not game.is_terminal(game_state):\n",
    "                #print(f\"\\nPlayer {game.get_player_turn(game_state)} making a move:\\n\")\n",
    "                # choose best action\n",
    "\n",
    "                if player_turn == 'X' and random_X:\n",
    "                    best_action = random.choice(game.get_actions(game_state))\n",
    "                elif player_turn == 'O' and random_O:\n",
    "                    best_action = random.choice(game.get_actions(game_state))\n",
    "                else:    \n",
    "                    #print(f\"running MCTS..\")\n",
    "                    best_action = mcts_solver.mcts(0.25, root_state=game_state, player_turn=player_turn)\n",
    "                \n",
    "                #print(f\"best action: {best_action}\")\n",
    "                # execute action \n",
    "                (game_state, reward) = game.execute(game_state, best_action)\n",
    "                # player for next turn\n",
    "                player_turn = game.get_player_turn(game_state) \n",
    "                #game.display_board(game_state)\n",
    "                steps += 1\n",
    "            \n",
    "            winner = game.get_winner(game_state)\n",
    "            winner = 'Draw' if winner == None else winner\n",
    "            wins[winner] = wins[winner] + 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'Game# {i} completed. Winner: {winner}, Player X win rate: {wins[\"X\"]/num_games}, Player O win rate: {wins[\"O\"]/num_games}, Draw rate: {wins[\"Draw\"]/num_games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 250/250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 249 completed. Winner: O, Player X win rate: 0.556, Player O win rate: 0.32, Draw rate: 0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(250, random_X=True, random_O=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 999 completed. Winner: Draw, Player X win rate: 0.009, Player O win rate: 0.01, Draw rate: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(1000, random_X=False, random_O=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 250/250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 249 completed. Winner: Draw, Player X win rate: 0.084, Player O win rate: 0.188, Draw rate: 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(250, random_X=True, random_O=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 250/250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 249 completed. Winner: X, Player X win rate: 0.668, Player O win rate: 0.068, Draw rate: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(250, random_X=False, random_O=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# instantiate ganme object\n",
    "game = TicTacToe()\n",
    "\n",
    "# instantiate bandit\n",
    "bandit = UCBBandit()\n",
    "\n",
    "# instantiate MCTS solver\n",
    "mcts_solver = MCTS(game, bandit)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# run mcts solver\n",
    "root_node = mcts_solver.create_root_node()\n",
    "best_action = mcts_solver.mcts(1, root_node)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now define an MCTS class for the tic tac toe game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class MCTS:\\n    def __init__(self, game, exploration_weight=1.0):\\n        self.game = game\\n\\n        # dictionary for storing value/total reward at each node\\n        self.Q = defaultdict(int)\\n        # dictionary for storing visit counts for each node\\n        self.visited = defaultdict(int)\\n        # dictionary for storing children of expanded nodes\\n        self.children = dict()\\n        self.exploration_weight = exploration_weight\\n\\n                    \\n    # choose a move in the game \\n    def choose_move(self, node):\\n        # make sure the state is not terminal\\n        if self.game.is_terminal(node.state):\\n            raise RuntimeError(f\"choose called on terminal state: {node.state}\")\\n        \\n        if node not in self.children:\\n            # randomly pick a successor state\\n            return random.choice(self.game.get_successors(node.state))\\n        \\n        def score(n):\\n            if self.N[n] == 0:\\n                return float(\"-inf\") # unseen moves have lowest possible value\\n            else:\\n                return self.Q[n] / self.N[n] # average reward\\n\\n        # return child with best value\\n        return max(self.children[node], key=score)\\n\\n\\n    # traverse down from a node and select a descendent node which has not been fully expanded yet\\n    def select(self, node):\\n        path = []\\n        while True:\\n            path.append(node)\\n            if node not in self.children or not self.children[node]:\\n                # node is either unexplored/unexpanded or terminal (i.e. node has no children)\\n                return path\\n            # get unexpanded nodes \\n            unexplored = self.children[node] - self.children.keys()\\n            if unexplored:\\n                n = unexplored.pop()\\n                path.append(n)\\n                return path\\n            \\n            # if all children expanded, need to go another level deeper, select child using UCB bandit\\n            node = self.ucb_select(node)\\n            \\n\\n    # select successor node using ucb bandit\\n    def ucb_select(self, node):\\n        log_N = math.log(self.N[node])\\n        def ucb(n):\\n            return self.Q[n]/self.N[n] + self.exploration_weight * math.sqrt(log_N/self.N[n])\\n        \\n        return max(self.children[node], key=ucb)\\n\\n\\n    # update the children dictionary with the children of node\\n    def expand(self, node):\\n        # node already expanded\\n        if node in self.children:\\n            return\\n        self.children[node] = self.game.get_successors(node.state)\\n    \\n\\n    # run simulation until terminal state reached (actions are chosen randomly)\\n    def simulate(self, node):\\n        state = node.state\\n        invert_reward = True\\n\\n        while True:\\n\\n            if self.game.is_terminal(node.state):\\n                reward = self.game.get_reward(state)\\n                return 1- reward if invert_reward else reward \\n            \\n            # randomly pick a successor\\n            node = random.choice(self.game.get_successors(node.state))\\n            invert_reward = not invert_reward\\n\\n\\n\\n    # performs mcts from specified root node (timeout in seconds)\\n    def mcts(self, timeout=1, root_node=None):\\n        # create a root node if none provided\\n        if root_node == None:\\n            root_node = self.create_root_node()\\n\\n        # start the timer\\n        start_time = time.time()\\n        current_time = time.time()\\n        num_iterations = 0\\n\\n        # perform mcts iterations until timeout\\n        while current_time < start_time + timeout:\\n\\n            # select node for expansion\\n            selected_node = root_node.select()\\n            \\n            if not (self.mdp.is_exit(selected_node.state)):\\n\\n                # expand the selected node to generate a child node (if the node is not a terminal state)\\n                child = selected_node.expand()\\n\\n                # run simulation to get a reward\\n                reward = self.simulate(child)\\n\\n                # backpropagate the reward to root node\\n                selected_node.backpropagate(reward, child) \\n\\n            current_time = time.time()      \\n            num_iterations += 1    \\n\\n\\n        print(f\"MCTS iterations: {num_iterations}\")\\n\\n        # update value function and display the table\\n        self.qfunction.update_V_from_Q()\\n        self.qfunction.display()  \\n\\n        return root_node\\n \\n\\n\\n    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\\n    def backpropagate(self, G, child):\\n        # get the action which generated the child\\n        action = child.action\\n\\n        # update number of times visited for both the state (white) node and state-action (black) node\\n        Node.visits[self.state] = Node.visits[self.state] + 1\\n        Node.visits[(self.state, action)] = Node.visits[(self.state, action)] + 1\\n\\n        # get current Q value \\n        qvalue = self.qfunction.evaluate(self.state, action)\\n        # compute update delta\\n        delta = (G - self.qfunction.evaluate(self.state, action)) / Node.visits[(self.state, action)]\\n        # update the Q value\\n        self.qfunction.update(self.state, action, qvalue, delta)\\n\\n        # recursively backpropagate until root node is reached\\n        if self.parent != None:\\n            self.parent.backpropagate(self.reward + G, self)\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class MCTS:\n",
    "    def __init__(self, game, exploration_weight=1.0):\n",
    "        self.game = game\n",
    "\n",
    "        # dictionary for storing value/total reward at each node\n",
    "        self.Q = defaultdict(int)\n",
    "        # dictionary for storing visit counts for each node\n",
    "        self.visited = defaultdict(int)\n",
    "        # dictionary for storing children of expanded nodes\n",
    "        self.children = dict()\n",
    "        self.exploration_weight = exploration_weight\n",
    "\n",
    "                    \n",
    "    # choose a move in the game \n",
    "    def choose_move(self, node):\n",
    "        # make sure the state is not terminal\n",
    "        if self.game.is_terminal(node.state):\n",
    "            raise RuntimeError(f\"choose called on terminal state: {node.state}\")\n",
    "        \n",
    "        if node not in self.children:\n",
    "            # randomly pick a successor state\n",
    "            return random.choice(self.game.get_successors(node.state))\n",
    "        \n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\") # unseen moves have lowest possible value\n",
    "            else:\n",
    "                return self.Q[n] / self.N[n] # average reward\n",
    "\n",
    "        # return child with best value\n",
    "        return max(self.children[node], key=score)\n",
    "\n",
    "\n",
    "    # traverse down from a node and select a descendent node which has not been fully expanded yet\n",
    "    def select(self, node):\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored/unexpanded or terminal (i.e. node has no children)\n",
    "                return path\n",
    "            # get unexpanded nodes \n",
    "            unexplored = self.children[node] - self.children.keys()\n",
    "            if unexplored:\n",
    "                n = unexplored.pop()\n",
    "                path.append(n)\n",
    "                return path\n",
    "            \n",
    "            # if all children expanded, need to go another level deeper, select child using UCB bandit\n",
    "            node = self.ucb_select(node)\n",
    "            \n",
    "\n",
    "    # select successor node using ucb bandit\n",
    "    def ucb_select(self, node):\n",
    "        log_N = math.log(self.N[node])\n",
    "        def ucb(n):\n",
    "            return self.Q[n]/self.N[n] + self.exploration_weight * math.sqrt(log_N/self.N[n])\n",
    "        \n",
    "        return max(self.children[node], key=ucb)\n",
    "\n",
    "\n",
    "    # update the children dictionary with the children of node\n",
    "    def expand(self, node):\n",
    "        # node already expanded\n",
    "        if node in self.children:\n",
    "            return\n",
    "        self.children[node] = self.game.get_successors(node.state)\n",
    "    \n",
    "\n",
    "    # run simulation until terminal state reached (actions are chosen randomly)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        invert_reward = True\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if self.game.is_terminal(node.state):\n",
    "                reward = self.game.get_reward(state)\n",
    "                return 1- reward if invert_reward else reward \n",
    "            \n",
    "            # randomly pick a successor\n",
    "            node = random.choice(self.game.get_successors(node.state))\n",
    "            invert_reward = not invert_reward\n",
    "\n",
    "\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, root_node=None):\n",
    "        # create a root node if none provided\n",
    "        if root_node == None:\n",
    "            root_node = self.create_root_node()\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout:\n",
    "\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            \n",
    "            if not (self.mdp.is_exit(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                selected_node.backpropagate(reward, child) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "\n",
    "        print(f\"MCTS iterations: {num_iterations}\")\n",
    "\n",
    "        # update value function and display the table\n",
    "        self.qfunction.update_V_from_Q()\n",
    "        self.qfunction.display()  \n",
    "\n",
    "        return root_node\n",
    " \n",
    "\n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G, child):\n",
    "        # get the action which generated the child\n",
    "        action = child.action\n",
    "\n",
    "        # update number of times visited for both the state (white) node and state-action (black) node\n",
    "        Node.visits[self.state] = Node.visits[self.state] + 1\n",
    "        Node.visits[(self.state, action)] = Node.visits[(self.state, action)] + 1\n",
    "\n",
    "        # get current Q value \n",
    "        qvalue = self.qfunction.evaluate(self.state, action)\n",
    "        # compute update delta\n",
    "        delta = (G - self.qfunction.evaluate(self.state, action)) / Node.visits[(self.state, action)]\n",
    "        # update the Q value\n",
    "        self.qfunction.update(self.state, action, qvalue, delta)\n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(self.reward + G, self)\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
