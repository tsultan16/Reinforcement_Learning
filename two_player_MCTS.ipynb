{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "import math, time, random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-player Monte Carlo Tree Search: For turn based games where actions are alternatingly carried out by an agent and it's opponent. We will demonstrate monte carlo search using the Tic Tac Toe game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class for a tic tac toe game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = '-'\n",
    "CIRCLE = 'O'\n",
    "CROSS = 'X'\n",
    "\n",
    "class TicTacToe:\n",
    "\n",
    "    def __init__(self, gamma = 1.0):\n",
    "        self.players = [CIRCLE, CROSS]\n",
    "        self.CROSS = CROSS\n",
    "        self.CIRCLE = CIRCLE\n",
    "        self.gamma = 1.0\n",
    "\n",
    "    # get list of players\n",
    "    def get_players(self):\n",
    "        return self.players\n",
    "    \n",
    "    \n",
    "    def get_opponent(self, player):\n",
    "        if player == CIRCLE:\n",
    "            opponent = CROSS\n",
    "        else:\n",
    "            opponent = CIRCLE \n",
    "        return opponent       \n",
    "    \n",
    "    \n",
    "    # get all valid actions from a state (a valid action is just an empty position on the board which can be marked by a player)\n",
    "    def get_actions(self, state):\n",
    "        board = state\n",
    "        actions = []\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    actions += [(i,j)]\n",
    "            \n",
    "        return actions\n",
    "\n",
    "\n",
    "    # make deep copy of a state\n",
    "    def copy(self, state):\n",
    "        next_state = []\n",
    "        for i in range(len(state)):\n",
    "            new_row = []\n",
    "            for j in range(len(state[i])):\n",
    "                new_row += [state[i][j]]\n",
    "            next_state += [new_row]    \n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "\n",
    "    # return the reward and state reulting from playing an action from a state\n",
    "    def execute(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return (next_state, self.get_reward(next_state))\n",
    "\n",
    "\n",
    "    # return the state reulting from playing an action from a state\n",
    "    def get_transition(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return next_state\n",
    "\n",
    "\n",
    "    # return all possible successors from the state\n",
    "    def get_successors(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            # if game is finished, there's no successor states\n",
    "            return set()\n",
    "        else:\n",
    "            successors = []\n",
    "            actions = self.get_actions(state)\n",
    "            for action in actions:\n",
    "                successors += [self.get_transition(state, action)]\n",
    "            \n",
    "            return successors\n",
    "\n",
    "\n",
    "    # return the reward for transitioning into the state\n",
    "    def get_reward(self, state):\n",
    "        winner = self.get_winner(state)\n",
    "        if winner == None:\n",
    "            #return {CROSS: 0.5, CIRCLE: 0.5}\n",
    "            return {CROSS: 0.0, CIRCLE: 0.0}\n",
    "        \n",
    "        elif winner == CROSS:\n",
    "            return {CROSS: 1.0, CIRCLE: -1.0}\n",
    "\n",
    "        elif winner == CIRCLE:\n",
    "            return {CROSS: -1.0, CIRCLE: 1.0}\n",
    "\n",
    "\n",
    "    # count how many empty positions on the board\n",
    "    def count_empty(self, board):\n",
    "        empty = 0\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    empty += 1\n",
    "\n",
    "        return empty\n",
    "    \n",
    "    # return true iff state is a terminal state of the game\n",
    "    def is_terminal(self, state):\n",
    "        #if self.get_winner(state) != None:\n",
    "        #    print(f\"The winner is : {self.get_winner(state)}\")\n",
    "\n",
    "        return self.count_empty(state)==0 or self.get_winner(state) != None\n",
    "    \n",
    "    # return player who gets to select the action at current state, i.e. whose turn it is\n",
    "    def get_player_turn(self, state):\n",
    "        board = state\n",
    "        # cross always starts the game, so crosses turn if there are an odd number of empty cells (9 cells total)\n",
    "        empty = self.count_empty(board)\n",
    "        if empty %2 == 0:\n",
    "            return CIRCLE\n",
    "        else:\n",
    "            return CROSS\n",
    "\n",
    "\n",
    "    # initial state of the game (empty board)\n",
    "    def initial_state(self):\n",
    "        board = [[EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY]]\n",
    "\n",
    "        return board\n",
    "\n",
    "    def get_winner(self, state):\n",
    "        board = state\n",
    "\n",
    "        # check columns\n",
    "        for i in range(len(board)):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board[i]):\n",
    "                return CROSS      \n",
    "            elif circles == len(board[i]):\n",
    "                return CIRCLE \n",
    "       \n",
    "        # check rows\n",
    "        for j in range(len(board[0])):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for i in range(len(board)):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board):\n",
    "                return CROSS      \n",
    "            elif circles == len(board):\n",
    "                return CIRCLE \n",
    "\n",
    "        # check top-left to bottom-right diagonal\n",
    "        if board[0][0] == CIRCLE and board[1][1] == CIRCLE and board[2][2] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][0] == CROSS and board[1][1] == CROSS and board[2][2] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # check top-right to bottom-left diagonal\n",
    "        if board[0][2] == CIRCLE and board[1][1] == CIRCLE and board[2][0] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][2] == CROSS and board[1][1] == CROSS and board[2][0] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # no winner\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # format the board into a string\n",
    "    def display_board(self, state):\n",
    "        for row in state:\n",
    "            for i in range(len(row)):        \n",
    "                if i < len(row)-1:\n",
    "                    print(row[i], end=' | ')\n",
    "                else:\n",
    "                    print(row[i], end='')    \n",
    "            print()\n",
    "\n",
    "\n",
    "    '''\n",
    "    def game_tree(self):\n",
    "        return self.state_to_node(self.get_initial_state())\n",
    "    \n",
    "\n",
    "    def state_to_node(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            return GameNode(state, None, self.get_reward(state))\n",
    "        \n",
    "        player = self.get_player_turn(state)\n",
    "        children = dict()\n",
    "        for action in self.get_actions(state):\n",
    "            next_state = self.get_transition(state, action)\n",
    "            child_node = self.state_to_node(next_state)\n",
    "            children[action] = child_node\n",
    "        \n",
    "        return GameNode(state, player, None, children)    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a base class for game tree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "\n",
    "    # static counter for node IDs\n",
    "    next_node_id = 0\n",
    "\n",
    "    # static dictionary for recording the number of times each node in the tree has been visited\n",
    "    visits = defaultdict(lambda: 0)\n",
    "\n",
    "    def __init__(self, game, state, parent, player_turn, bandit, value=0.0, reward=0.0, is_best_action=False, children=dict(), action=None):\n",
    "        self.game = game\n",
    "        self.state = state\n",
    "        self.parent = parent            # pointer to parent node\n",
    "        self.player_turn = player_turn  # marks which player's turn is on that state\n",
    "        self.value = value\n",
    "        self.reward = reward\n",
    "        self.bandit = bandit\n",
    "        self.is_best_action = is_best_action\n",
    "        self.children = dict()\n",
    "        self.action = action # action which generated the child\n",
    "        self.accumulated_rewards = 0.0\n",
    "\n",
    "        self.id = GameNode.next_node_id\n",
    "        GameNode.next_node_id += 1\n",
    "        \n",
    "\n",
    "    # recursively traverse the tree and select a node that has not been fully expanded yet\n",
    "    def select(self):\n",
    "\n",
    "        if not self.is_fully_expanded() or self.game.is_terminal(self.state):\n",
    "            # stop recursion when we've found node which hasn't been fully expanded or is terminal state\n",
    "            return self\n",
    "        else:\n",
    "            # use the bandit to select the next child\n",
    "            actions = list(self.children.keys())\n",
    "            values = {action:self.children[action].get_value() for action in actions}\n",
    "            parent_visits = GameNode.visits[self.id]\n",
    "            children_visits = {action:GameNode.visits[self.children[action].id] for action in actions}\n",
    "            action =  self.bandit.select(actions, values, parent_visits, children_visits)\n",
    "            return self.children[action].select()  \n",
    "\n",
    "\n",
    "    # checks if a node has been fully expanded\n",
    "    def is_fully_expanded(self):    \n",
    "        valid_actions = self.game.get_actions(self.state)\n",
    "        if(len(valid_actions) == len(self.children)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    # expand a node (only generate one child, not all children) if it's a non terminal-state\n",
    "    def expand(self):\n",
    "        if not self.game.is_terminal(self.state):\n",
    "\n",
    "            #print(f\"Expanding node id: {self.id}\")\n",
    "\n",
    "            # randomly select an unexpanded action to expand\n",
    "            valid_actions = self.game.get_actions(self.state)\n",
    "            #print(f\"Available actions: {valid_actions}, already expanded children actions: {list(self.children.keys())}\")\n",
    "\n",
    "            unexplored_actions = list(valid_actions - self.children.keys())\n",
    "            #print(f\"Unexplored actions: {unexplored_actions}\")\n",
    "\n",
    "            #if len(unexplored_actions) > 0:\n",
    "            action = random.choice(unexplored_actions)\n",
    "            #else:\n",
    "            #    action = random.choice(list(self.children.keys()))\n",
    "\n",
    "            #print(f\"randomly chosen action = {action}\")\n",
    "            # create a slot for that action in the children dictionary\n",
    "            #self.children[action] = []\n",
    "\n",
    "            # create a new child node and add to children dictionary\n",
    "            (child_state, reward) = self.game.execute(self.state, action)            \n",
    "            player_turn = self.game.get_player_turn(child_state)\n",
    "            new_child = GameNode(self.game, child_state, self, player_turn, self.bandit, reward=reward, action=action)    \n",
    "            \n",
    "            self.children[action] = new_child  # each action leads to only one child \n",
    "            #print(f\"generated child id: {new_child.id}, expanded children actions: {list(new_child.children.keys())}\")\n",
    "            \n",
    "            #print(f\"Genereated child node id: {self.children[action].id}, action: {action}, board state:\")\n",
    "            #self.game.display_board(self.children[action].state)\n",
    "            \n",
    "            return new_child                   \n",
    "        \n",
    "        # for terminal state, can't expand further\n",
    "        return self\n",
    "    \n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G):\n",
    "\n",
    "        # update number of times visited for the state\n",
    "        GameNode.visits[self.id] = GameNode.visits[self.id] + 1\n",
    "\n",
    "        # apply discount to the backpropagated reward\n",
    "        discounted_G = {}\n",
    "        for player in G:\n",
    "            discounted_G[player] = G[player] * self.game.gamma   \n",
    "\n",
    "        # update the accumulated reward\n",
    "        #simulation_reward = discounted_G[self.player_turn]  \n",
    "        simulation_reward = discounted_G[self.game.get_opponent(self.player_turn)]  # this seems to make it work, even though it's the opposite of what it should be ... \n",
    "        self.accumulated_rewards += simulation_reward \n",
    "\n",
    "        #print(f\"Backpropagation. Node id: {self.id}, visited: {GameNode.visits[self.id]}, accumulated reward: {self.accumulated_rewards}\")\n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(discounted_G)\n",
    "\n",
    "\n",
    "    # return value of this node\n",
    "    def get_value(self):\n",
    "        return self.accumulated_rewards / GameNode.visits[self.id] \n",
    "\n",
    "\n",
    "\n",
    "# upper confidence bounds (UCB) bandit\n",
    "class UCBBandit:\n",
    "    def __init__(self, exploration_param = 1.0):\n",
    "        self.total = 0\n",
    "        # dictionary for recording number of times each action has been chosen\n",
    "        self.times_selected = {}\n",
    "        self.exploration_param = exploration_param\n",
    "\n",
    "\n",
    "    def select(self, actions, values, parent_visits, children_visits):\n",
    "\n",
    "        max_actions = []\n",
    "        max_value = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            # avoid division by zero\n",
    "            if children_visits[action] == 0 or parent_visits == 0:\n",
    "                value = float(\"inf\")\n",
    "            else: \n",
    "                value = values[action] + self.exploration_param * math.sqrt(2.0*math.log(parent_visits)/children_visits[action])\n",
    "                \n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_actions = [action]\n",
    "            elif value == max_value:\n",
    "                max_actions.append(action)\n",
    "\n",
    "        # if multiple actions with max value, pick one randomly\n",
    "        selected_action = random.choice(max_actions)\n",
    "        \n",
    "        return selected_action    \n",
    "    \n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, bandit):\n",
    "        self.game = game\n",
    "        self.bandit = bandit\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, initial_root_node=None, root_state=None, player_turn=None):\n",
    "        # create a root node if none provided\n",
    "        #if root_node == None:\n",
    "        root_node = self.create_root_node(root_state=root_state, player_turn=player_turn)\n",
    "        #root_node = GameNode(self.game, root_state, None, player_turn, self.bandit)  \n",
    "        #root_node.children = dict()\n",
    "        #print(f\"root node id: {root_node.id}, children: {list(root_node.children.keys())}\")\n",
    "        #print(f\"Initial game state:\")\n",
    "        #self.game.display_board(root_state)\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout and num_iterations<400:\n",
    "\n",
    "            #print(f\"MCTS iteration # {num_iterations}\")\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            #print(f\"selected node id: {selected_node.id}\")\n",
    "\n",
    "            if not (self.game.is_terminal(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "                #print(f\"Child node id: {child.id}\")\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "                #print(f\"Simulation rewards: {reward}\")\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                child.backpropagate(reward) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "        #print(f\"MCTS iterations: {num_iterations}\")\n",
    "        # after finishing mcts iterations, find the best action\n",
    "        best_action = self.get_best_action(root_node)\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    # get the best action from the root node\n",
    "    def get_best_action(self, root_node):\n",
    "\n",
    "        #print(f\"choosing best action.. Root node id: {root_node.id}, Root node state:\")\n",
    "        #self.game.display_board(root_node.state)\n",
    "        #print(f\"Available children/actions: {list(root_node.children.keys())}\")\n",
    "\n",
    "        best_action = None\n",
    "        best_value = float(\"-inf\")\n",
    "        values = []\n",
    "        actions = []\n",
    "        for action in root_node.children:\n",
    "\n",
    "            actions.append(action)\n",
    "            #print(f\"Child node id: {root_node.children[action].id}, action: {action}, board state:\")\n",
    "            #self.game.display_board(root_node.children[action].state)\n",
    "\n",
    "            value = root_node.children[action].get_value()\n",
    "            values.append(value)\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_action = [action]\n",
    "            elif value == best_value:\n",
    "                best_action.append(action)\n",
    "\n",
    "        ''' \n",
    "        # softmax\n",
    "        temperature = 0.1 #0.9\n",
    "        # exponentiate the values\n",
    "        values_exp = []\n",
    "        for value in values:\n",
    "            if value > float(\"-inf\"):\n",
    "                values_exp.append(math.exp(value/temperature))\n",
    "            else:\n",
    "                values_exp.append(0.0)\n",
    "\n",
    "        sum_exp = sum(values_exp)\n",
    "        # if all scores are zero, then just pick a child at random\n",
    "        if sum_exp == 0.0:\n",
    "            return random.choice(root_node.children.keys())\n",
    "        # compute softmax distribution    \n",
    "        probabilities = [value_exp/sum_exp for value_exp in values_exp]   \n",
    "        # add a tiny bit of random noise to these probabilities\n",
    "        noise_magnitude = 0.00001 * (min(probabilities) + max (probabilities))\n",
    "        probabilities = [(p + noise_magnitude*random.random()) for p in probabilities]\n",
    "        # sample a child node according to this probability distribution\n",
    "        action_index = random.choices(range(len(probabilities)), probabilities)[0]\n",
    "        #print(f\"probabilities: {probabilities}, child_index = {child_index}\")\n",
    "        child_move = actions[action_index]\n",
    "        return child_move    \n",
    "        '''\n",
    "\n",
    "        # if multiple best actions, use random sampling\n",
    "        return random.choice(best_action)    \n",
    "\n",
    "\n",
    "    # create a root node representing the initial state\n",
    "    def create_root_node(self, root_state=None, player_turn=None):\n",
    "        if root_state == None:\n",
    "            return GameNode(self.game, self.game.initial_state(), None, self.game.CROSS, self.bandit) # cross gets first turn\n",
    "        else:\n",
    "            return GameNode(self.game, root_state, None, player_turn, self.bandit)  \n",
    "\n",
    "\n",
    "    # choose a random action for monte carlo simulation (can use a heuristic to choose actions instead of picking at random)\n",
    "    def choose(self, state):\n",
    "        actions = self.game.get_actions(state)\n",
    "        \n",
    "        # choose actions randomly\n",
    "        next_action = random.choice(actions)\n",
    "                \n",
    "        return next_action\n",
    "    \n",
    "    \n",
    "    # run simulation until terminal state reached (can be stopped after a fixed number of time steps instead of running until reaching terminal state)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        # the second entry in the reward vector is for opponent agent\n",
    "        player = node.player_turn\n",
    "        opponent = self.game.get_opponent(node.player_turn)\n",
    "        cumulative_reward = {player:0.0, opponent:0.0}\n",
    "        depth = 0\n",
    "\n",
    "        #print(f\"simulation initial state: \")\n",
    "        #self.game.display_board(state)\n",
    "        reward = None\n",
    "        while not self.game.is_terminal(state):\n",
    "            # choose an action to execute\n",
    "            action = self.choose(state)\n",
    "            # transition to next state\n",
    "            (next_state, reward) = self.game.execute(state, action)\n",
    "            # discount the rewards for my agent and opponent agent\n",
    "            cumulative_reward[player] = cumulative_reward[player] + pow(self.game.gamma, depth) * reward[player] \n",
    "            cumulative_reward[opponent] = cumulative_reward[opponent] +pow(self.game.gamma, depth) * reward[opponent] \n",
    "            depth += 1\n",
    "            state = next_state\n",
    "\n",
    "            #print(f\"Next state: \")\n",
    "            #self.game.display_board(state)\n",
    "        #print(f\"Terminal state reached! Simulation completed. Rewards: {reward}\")\n",
    "        return cumulative_reward    \n",
    "    \n",
    "\n",
    "# self play function\n",
    "def self_play(num_games, random_X=False, random_O=False):\n",
    "\n",
    "    # instantiate ganme object\n",
    "    game = TicTacToe()\n",
    "    # instantiate bandit\n",
    "    bandit = UCBBandit()\n",
    "    # instantiate MCTS solver\n",
    "    mcts_solver1 = MCTS(game, bandit)\n",
    "    mcts_solver2 = MCTS(game, bandit)\n",
    "\n",
    "    wins = {'X':0, 'O':0, 'Draw':0}\n",
    "    \n",
    "    with tqdm(total=num_games, ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "\n",
    "        # first turn goes to X\n",
    "        player_turn = 'X'\n",
    "        for i in range(num_games):\n",
    "            steps = 0\n",
    "            game_state = game.initial_state()\n",
    "            #print(f\"Starting game # {i}\")\n",
    "            while not game.is_terminal(game_state):\n",
    "                #print(f\"\\nPlayer {game.get_player_turn(game_state)} making a move:\\n\")\n",
    "                # choose best action\n",
    "\n",
    "                if player_turn == 'X':\n",
    "                    if random_X:\n",
    "                        best_action = random.choice(game.get_actions(game_state))\n",
    "                    else:\n",
    "                        best_action = mcts_solver1.mcts(root_state=game_state, player_turn=player_turn)\n",
    "                \n",
    "                elif player_turn == 'O': \n",
    "                    if random_O:\n",
    "                        best_action = random.choice(game.get_actions(game_state))\n",
    "                    else:    \n",
    "                        best_action = mcts_solver2.mcts(root_state=game_state, player_turn=player_turn)\n",
    "                \n",
    "\n",
    "                #print(f\"best action: {best_action}\")\n",
    "                # execute action \n",
    "                (game_state, reward) = game.execute(game_state, best_action)\n",
    "                # player for next turn\n",
    "                player_turn = game.get_player_turn(game_state) \n",
    "                #game.display_board(game_state)\n",
    "                steps += 1\n",
    "            \n",
    "            winner = game.get_winner(game_state)\n",
    "            winner = 'Draw' if winner == None else winner\n",
    "            wins[winner] = wins[winner] + 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'Game# {i} completed. Winner: {winner}, Player X win rate: {wins[\"X\"]/num_games}, Player O win rate: {wins[\"O\"]/num_games}, Draw rate: {wins[\"Draw\"]/num_games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 500/500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 499 completed. Winner: X, Player X win rate: 0.562, Player O win rate: 0.296, Draw rate: 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(500, random_X=True, random_O=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 300/300"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 299 completed. Winner: X, Player X win rate: 0.27, Player O win rate: 0.3466666666666667, Draw rate: 0.38333333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(300, random_X=False, random_O=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 300/300"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 299 completed. Winner: Draw, Player X win rate: 0.25, Player O win rate: 0.58, Draw rate: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(300, random_X=True, random_O=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 300/300"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 299 completed. Winner: Draw, Player X win rate: 0.7233333333333334, Player O win rate: 0.14666666666666667, Draw rate: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(300, random_X=False, random_O=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 3000/3000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game# 2999 completed. Winner: X, Player X win rate: 0.693, Player O win rate: 0.13666666666666666, Draw rate: 0.17033333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "self_play(3000, random_X=False, random_O=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# instantiate ganme object\\ngame = TicTacToe()\\n\\n# instantiate bandit\\nbandit = UCBBandit()\\n\\n# instantiate MCTS solver\\nmcts_solver = MCTS(game, bandit)'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# instantiate ganme object\n",
    "game = TicTacToe()\n",
    "\n",
    "# instantiate bandit\n",
    "bandit = UCBBandit()\n",
    "\n",
    "# instantiate MCTS solver\n",
    "mcts_solver = MCTS(game, bandit)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# run mcts solver\\nroot_node = mcts_solver.create_root_node()\\nbest_action = mcts_solver.mcts(1, root_node)'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# run mcts solver\n",
    "root_node = mcts_solver.create_root_node()\n",
    "best_action = mcts_solver.mcts(1, root_node)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
