{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import *\n",
    "import math, time, random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-player Monte Carlo Tree Search: For turn based games where actions are alternatingly carried out by an agent and it's opponent. We will demonstrate monte carlo search using the Tic Tac Toe game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a base class for game tree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameNode:\n",
    "\n",
    "    # static counter for node IDs\n",
    "    next_node_id = 0\n",
    "\n",
    "    # static dictionary for recording the number of times each node in the tree has been visited\n",
    "    visits = defaultdict(lambda: 0)\n",
    "\n",
    "    def __init__(self, game, state, player_turn, bandit, value=0.0, reward=0.0, is_best_action=False, children=dict(), action=None):\n",
    "        self.game = game\n",
    "        self.state = state\n",
    "        self.player_turn = player_turn  # marks which player's turn is on that state\n",
    "        self.value = value\n",
    "        self.reward = reward\n",
    "        self.bandit = bandit\n",
    "        self.is_best_action = is_best_action\n",
    "        self.children = children\n",
    "        self.action = action # action which generated the child\n",
    "        self.accumulated_rewards = 0.0\n",
    "\n",
    "        self.id = GameNode.next_node_id\n",
    "        GameNode.next_node_id += 1\n",
    "        \n",
    "\n",
    "    # recursively traverse the tree and select a node that has not been fully expanded yet\n",
    "    def select(self):\n",
    "\n",
    "        if not self.is_fully_expanded() or self.game.is_terminal(self.state):\n",
    "            # stop recursion when we've found node which hasn't been fully expanded or is terminal state\n",
    "            return self\n",
    "        else:\n",
    "            # use the bandit to select the next child\n",
    "            actions = list(self.children.keys())\n",
    "            values = {action:self.children[action].get_value() for action in actions}\n",
    "            action =  self.bandit.select(actions, values)\n",
    "            return self.children[action].select()  \n",
    "\n",
    "\n",
    "    # checks if a node has been fully expanded\n",
    "    def is_fully_expanded(self):    \n",
    "        actions = self.game.get_actions(self.state)\n",
    "        if(len(actions) == len(self.children)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    # expand a node if it's a non terminal-state\n",
    "    def expand(self):\n",
    "        if not self.game.is_terminal(self.state):\n",
    "\n",
    "            # randomly select an unexpanded action to expand\n",
    "            unexplored_actions = self.game.get_actions(self.state) - self.children.keys()\n",
    "            action = random.choice(list(unexplored_actions))\n",
    "            \n",
    "            # create a slot for that action in the children dictionary\n",
    "            self.children[action] = []\n",
    "\n",
    "            # create a new child node and add to children dictionary\n",
    "            (child_state, reward) = self.game.execute(self.state, action)\n",
    "            new_child = GameNode(self.game, child_state, self.game.get_opponent(self.player_turn), self.bandit, reward=reward, action=action)     \n",
    "            self.children[action] += [new_child]\n",
    "            return new_child                   \n",
    "        \n",
    "        # for terminal state, can't expand further\n",
    "        return self\n",
    "    \n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G, child):\n",
    "        # get the action which generated the child\n",
    "        action = child.action\n",
    "\n",
    "        # update number of times visited for both the state (white) node and state-action (black) node\n",
    "        GameNode.visits[self.state] = GameNode.visits[self.state] + 1\n",
    "\n",
    "        # apply discount to the backpropagated reward\n",
    "        discounted_G = {}\n",
    "        for player in G:\n",
    "            discounted_G[player] = G[player] * self.game.gamma   \n",
    "\n",
    "        # update the accumulated reward\n",
    "        simulation_reward = discounted_G[self.player_turn]\n",
    "        self.accumulated_rewards += simulation_reward \n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(discounted_G, self)\n",
    "\n",
    "\n",
    "    # return value of this node\n",
    "    def get_value(self):\n",
    "        return self.accumulated_rewards / GameNode.visits[self.state] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# upper confidence bounds (UCB) bandit\n",
    "class UCBBandit:\n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        # dictionary for recording number of times each action has been chosen\n",
    "        self.times_selected = {}\n",
    "\n",
    "\n",
    "    def select(self, actions, values):\n",
    "        \n",
    "        # first, make sure each action has been executed once\n",
    "        for action in actions:\n",
    "            if action not in self.times_selected.keys():\n",
    "                self.times_selected[action] = 1\n",
    "                self.total += 1\n",
    "                return action\n",
    "\n",
    "        max_actions = []\n",
    "        max_value = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            value = values[action] + math.sqrt(2.0*math.log(self.total)/self.times_selected[action])\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_actions = [action]\n",
    "            elif value == max_value:\n",
    "                max_actions.append(action)\n",
    "\n",
    "        # if multiple actions with max value, pick one randomly\n",
    "        selected_action = random.choice(max_actions)\n",
    "        self.times_selected[selected_action] = self.times_selected[selected_action] + 1\n",
    "        self.total += 1\n",
    "        \n",
    "        return selected_action    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, game, bandit):\n",
    "        self.game = game\n",
    "        self.bandit = bandit\n",
    "\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, root_node=None):\n",
    "        # create a root node if none provided\n",
    "        if root_node == None:\n",
    "            root_node = self.create_root_node()\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout:\n",
    "\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            \n",
    "            if not (self.mdp.is_exit(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                selected_node.backpropagate(reward, child) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "\n",
    "        print(f\"MCTS iterations: {num_iterations}\")\n",
    "\n",
    "        # update value function and display the table\n",
    "        self.qfunction.update_V_from_Q()\n",
    "        self.qfunction.display()  \n",
    "\n",
    "        return root_node\n",
    "\n",
    "\n",
    "    # createa a root node representing the initial state\n",
    "    def create_root_node(self): abstractmethod       \n",
    "\n",
    "\n",
    "    # choose a random action for monte carlo simulation (can use a heuristic to choose actions instead of picking at random)\n",
    "    def choose(self, state):\n",
    "        actions = self.game.get_actions(state)\n",
    "        \n",
    "        # choose actions randomly\n",
    "        next_action = random.choice(actions)\n",
    "        \n",
    "        # heuristic based:  choose action that can lead to a state with highest immediate reward\n",
    "        '''\n",
    "        max_reward = float(\"-inf\")\n",
    "        max_actions = [] \n",
    "        for action in actions:\n",
    "            transitions = self.mdp.get_transitions(state, action)\n",
    "            for (next_state, _) in transitions:\n",
    "                reward = self.mdp.get_rewards(state, action, next_state)\n",
    "                if reward > max_reward:\n",
    "                    max_reward = reward\n",
    "                    max_actions = [action]\n",
    "                elif reward == max_reward:\n",
    "                    max_actions.append(action)\n",
    "\n",
    "        # if multiple actions lead to best reward state,. pick one randomly\n",
    "        next_action = random.choice(max_actions)                 \n",
    "        '''\n",
    "        \n",
    "        return next_action\n",
    "    \n",
    "    \n",
    "    # run simulation until terminal state reached (can be stopped after a fixed number of time steps instead of running until reaching terminal state)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        # the second entry in the reward vector is for opponent agent\n",
    "        player = node.player_turn\n",
    "        opponent = self.game.get_opponent(node.player_turn)\n",
    "        cumulative_reward = {player:0.0, opponent:0.0}\n",
    "        depth = 0\n",
    "\n",
    "        while not self.game.is_terminal(state):\n",
    "            # choose an action to execute\n",
    "            action = self.choose(state)\n",
    "            # transition to next state\n",
    "            (next_state, reward) = self.game.execute(state, action)\n",
    "            # discount the rewards for my agent and opponent agent\n",
    "            cumulative_reward[player] = cumulative_reward[player] + pow(self.game.gamma, depth) * reward[player] \n",
    "            cumulative_reward[opponent] = cumulative_reward[opponent] +pow(self.game.gamma, depth) * reward[opponent] \n",
    "            depth += 1\n",
    "            state = next_state\n",
    "\n",
    "        return cumulative_reward    \n",
    "    \n",
    "\n",
    "    def create_root_node(self, root_state=None, player_turn=None):\n",
    "        if root_state == None:\n",
    "            return GameNode(self.game, self.game.get_initial_state(), self.game.CROSS, self.bandit)\n",
    "        else:\n",
    "            return GameNode(self.mdp, root_state, player_turn, self.bandit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class for the tic tac toe game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = ' '\n",
    "CIRCLE = 'O'\n",
    "CROSS = 'X'\n",
    "\n",
    "class TicTacToe:\n",
    "\n",
    "    def __init__(self, gamma = 1.0):\n",
    "        self.players = [CIRCLE, CROSS]\n",
    "        self.CROSS = CROSS\n",
    "        self.CIRCLE = CIRCLE\n",
    "        self.gamma = 1.0\n",
    "\n",
    "    # get list of players\n",
    "    def get_players(self):\n",
    "        return self.players\n",
    "    \n",
    "    \n",
    "    def get_opponent(self, player):\n",
    "        if player == CIRCLE:\n",
    "            opponent = CROSS\n",
    "        else:\n",
    "            opponent = CIRCLE \n",
    "        return opponent       \n",
    "    \n",
    "    \n",
    "    # get all valid actions from a state (a valid action is just an empty position on the board which can be marked by a player)\n",
    "    def get_actions(self, state):\n",
    "        board = state\n",
    "        actions = []\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    actions += [(i,j)]\n",
    "            \n",
    "        return actions\n",
    "\n",
    "\n",
    "    # make deep copy of a state\n",
    "    def copy(self, state):\n",
    "        next_state = []\n",
    "        for i in range(len(state)):\n",
    "            new_row = []\n",
    "            for j in range(len(state[i])):\n",
    "                new_row += [state[i][j]]\n",
    "            next_state += [new_row]    \n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "\n",
    "    # return the reward and state reulting from playing an action from a state\n",
    "    def execute(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return (next_state, self.get_reward(state))\n",
    "\n",
    "\n",
    "    # return the state reulting from playing an action from a state\n",
    "    def get_transition(self, state, action): \n",
    "        next_state = self.copy(state)\n",
    "        next_state[action[0]][action[1]] = self.get_player_turn(state)\n",
    "        \n",
    "        return next_state\n",
    "\n",
    "\n",
    "    # return all possible auccessors from the state\n",
    "    def get_successors(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            # if game is finished, there's no successor states\n",
    "            return set()\n",
    "        else:\n",
    "            successors = []\n",
    "            actions = self.get_actions(state)\n",
    "            for action in actions:\n",
    "                successors += [self.get_transition(state, action)]\n",
    "            \n",
    "            return successors\n",
    "\n",
    "\n",
    "    # return the reward for transitioning into the state\n",
    "    def get_reward(self, state):\n",
    "        winner = self.get_winner(state)\n",
    "        if winner == None:\n",
    "            return {CROSS: 0, CIRCLE: 0}\n",
    "        \n",
    "        elif winner == CROSS:\n",
    "            return {CROSS: 1, CIRCLE: 0}\n",
    "\n",
    "        elif winner == CIRCLE:\n",
    "            return {CROSS: 0, CIRCLE: 1}\n",
    "\n",
    "\n",
    "    # count how many empty positions on the board\n",
    "    def count_empty(self, board):\n",
    "        empty = 0\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == EMPTY:\n",
    "                    empty += 1\n",
    "\n",
    "        return empty\n",
    "    \n",
    "    # return true iff state is a terminal state of the game\n",
    "    def is_terminal(self, state):\n",
    "        return self.count_empty(state)==0 or self.get_winner(state) != None\n",
    "    \n",
    "    # return player who gets to select the action at current state, i.e. whose turn it is\n",
    "    def get_player_turn(self, state):\n",
    "        board = state\n",
    "        # cross always starts the game, so crosses turn if there are an odd number of empty cells (9 cells total)\n",
    "        empty = self.count_empty(board)\n",
    "        if empty %2 == 0:\n",
    "            return CIRCLE\n",
    "        else:\n",
    "            return CROSS\n",
    "\n",
    "\n",
    "    # initial state of the game (empty board)\n",
    "    def initial_state(self):\n",
    "        board = [[EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY], \n",
    "                 [EMPTY, EMPTY, EMPTY]]\n",
    "\n",
    "        return board\n",
    "\n",
    "    def get_winner(self, state):\n",
    "        board = state\n",
    "\n",
    "        # check rows\n",
    "        for i in range(len(board)):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for j in range(len(board[i])):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board[i]):\n",
    "                return CROSS      \n",
    "            elif circles == len(board[i]):\n",
    "                return CIRCLE \n",
    "       \n",
    "        # check columns\n",
    "        for j in range(len(board[0])):\n",
    "            circles = 0\n",
    "            crosses = 0\n",
    "            for i in range(len(board)):\n",
    "                if board[i][j] == CIRCLE:\n",
    "                    circles += 1\n",
    "                elif board[i][j] == CROSS:\n",
    "                    crosses += 1\n",
    "            if crosses == len(board):\n",
    "                return CROSS      \n",
    "            elif circles == len(board):\n",
    "                return CIRCLE \n",
    "\n",
    "        # check top-left to bottom-right diagonal\n",
    "        if board[0][0] == CIRCLE and board[1][1] == CIRCLE and board[2][2] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][0] == CROSS and board[1][1] == CROSS and board[2][2] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # check top-right to bottom-left diagonal\n",
    "        if board[0][2] == CIRCLE and board[1][1] == CIRCLE and board[2][0] == CIRCLE:\n",
    "            return CIRCLE\n",
    "        elif board[0][2] == CROSS and board[1][1] == CROSS and board[2][0] == CROSS:\n",
    "            return CROSS\n",
    "\n",
    "        # no winner\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # format the board into a string\n",
    "    def display_board(self, state):\n",
    "        for row in state:\n",
    "            for i in range(len(row)):        \n",
    "                if i < len(row)-1:\n",
    "                    print(row[i], end=' | ')\n",
    "                else:\n",
    "                    print(row[i], end='')    \n",
    "            print()\n",
    "\n",
    "    def game_tree(self):\n",
    "        return self.state_to_node(self.get_initial_state())\n",
    "    \n",
    "\n",
    "    def state_to_node(self, state):\n",
    "        if self.is_terminal(state):\n",
    "            return GameNode(state, None, self.get_reward(state))\n",
    "        \n",
    "        player = self.get_player_turn(state)\n",
    "        children = dict()\n",
    "        for action in self.get_actions(state):\n",
    "            next_state = self.get_transition(state, action)\n",
    "            child_node = self.state_to_node(next_state)\n",
    "            children[action] = child_node\n",
    "        \n",
    "        return GameNode(state, player, None, children)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now define an MCTS class for the tic tac toe game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class MCTS:\n",
    "    def __init__(self, game, exploration_weight=1.0):\n",
    "        self.game = game\n",
    "\n",
    "        # dictionary for storing value/total reward at each node\n",
    "        self.Q = defaultdict(int)\n",
    "        # dictionary for storing visit counts for each node\n",
    "        self.visited = defaultdict(int)\n",
    "        # dictionary for storing children of expanded nodes\n",
    "        self.children = dict()\n",
    "        self.exploration_weight = exploration_weight\n",
    "\n",
    "                    \n",
    "    # choose a move in the game \n",
    "    def choose_move(self, node):\n",
    "        # make sure the state is not terminal\n",
    "        if self.game.is_terminal(node.state):\n",
    "            raise RuntimeError(f\"choose called on terminal state: {node.state}\")\n",
    "        \n",
    "        if node not in self.children:\n",
    "            # randomly pick a successor state\n",
    "            return random.choice(self.game.get_successors(node.state))\n",
    "        \n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\") # unseen moves have lowest possible value\n",
    "            else:\n",
    "                return self.Q[n] / self.N[n] # average reward\n",
    "\n",
    "        # return child with best value\n",
    "        return max(self.children[node], key=score)\n",
    "\n",
    "\n",
    "    # traverse down from a node and select a descendent node which has not been fully expanded yet\n",
    "    def select(self, node):\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored/unexpanded or terminal (i.e. node has no children)\n",
    "                return path\n",
    "            # get unexpanded nodes \n",
    "            unexplored = self.children[node] - self.children.keys()\n",
    "            if unexplored:\n",
    "                n = unexplored.pop()\n",
    "                path.append(n)\n",
    "                return path\n",
    "            \n",
    "            # if all children expanded, need to go another level deeper, select child using UCB bandit\n",
    "            node = self.ucb_select(node)\n",
    "            \n",
    "\n",
    "    # select successor node using ucb bandit\n",
    "    def ucb_select(self, node):\n",
    "        log_N = math.log(self.N[node])\n",
    "        def ucb(n):\n",
    "            return self.Q[n]/self.N[n] + self.exploration_weight * math.sqrt(log_N/self.N[n])\n",
    "        \n",
    "        return max(self.children[node], key=ucb)\n",
    "\n",
    "\n",
    "    # update the children dictionary with the children of node\n",
    "    def expand(self, node):\n",
    "        # node already expanded\n",
    "        if node in self.children:\n",
    "            return\n",
    "        self.children[node] = self.game.get_successors(node.state)\n",
    "    \n",
    "\n",
    "    # run simulation until terminal state reached (actions are chosen randomly)\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        invert_reward = True\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if self.game.is_terminal(node.state):\n",
    "                reward = self.game.get_reward(state)\n",
    "                return 1- reward if invert_reward else reward \n",
    "            \n",
    "            # randomly pick a successor\n",
    "            node = random.choice(self.game.get_successors(node.state))\n",
    "            invert_reward = not invert_reward\n",
    "\n",
    "\n",
    "\n",
    "    # performs mcts from specified root node (timeout in seconds)\n",
    "    def mcts(self, timeout=1, root_node=None):\n",
    "        # create a root node if none provided\n",
    "        if root_node == None:\n",
    "            root_node = self.create_root_node()\n",
    "\n",
    "        # start the timer\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        num_iterations = 0\n",
    "\n",
    "        # perform mcts iterations until timeout\n",
    "        while current_time < start_time + timeout:\n",
    "\n",
    "            # select node for expansion\n",
    "            selected_node = root_node.select()\n",
    "            \n",
    "            if not (self.mdp.is_exit(selected_node.state)):\n",
    "\n",
    "                # expand the selected node to generate a child node (if the node is not a terminal state)\n",
    "                child = selected_node.expand()\n",
    "\n",
    "                # run simulation to get a reward\n",
    "                reward = self.simulate(child)\n",
    "\n",
    "                # backpropagate the reward to root node\n",
    "                selected_node.backpropagate(reward, child) \n",
    "\n",
    "            current_time = time.time()      \n",
    "            num_iterations += 1    \n",
    "\n",
    "\n",
    "        print(f\"MCTS iterations: {num_iterations}\")\n",
    "\n",
    "        # update value function and display the table\n",
    "        self.qfunction.update_V_from_Q()\n",
    "        self.qfunction.display()  \n",
    "\n",
    "        return root_node\n",
    " \n",
    "\n",
    "\n",
    "    # backpropagate reward back to root node (recursively update all nodes along the path to the root)\n",
    "    def backpropagate(self, G, child):\n",
    "        # get the action which generated the child\n",
    "        action = child.action\n",
    "\n",
    "        # update number of times visited for both the state (white) node and state-action (black) node\n",
    "        Node.visits[self.state] = Node.visits[self.state] + 1\n",
    "        Node.visits[(self.state, action)] = Node.visits[(self.state, action)] + 1\n",
    "\n",
    "        # get current Q value \n",
    "        qvalue = self.qfunction.evaluate(self.state, action)\n",
    "        # compute update delta\n",
    "        delta = (G - self.qfunction.evaluate(self.state, action)) / Node.visits[(self.state, action)]\n",
    "        # update the Q value\n",
    "        self.qfunction.update(self.state, action, qvalue, delta)\n",
    "\n",
    "        # recursively backpropagate until root node is reached\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(self.reward + G, self)\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
